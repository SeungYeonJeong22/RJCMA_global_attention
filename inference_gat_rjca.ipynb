{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실행 순서\n",
    "\n",
    "1. 1셀 test_weight_file 필요한 시드 웨이트 파일로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "test_weight_file = \"1210_1715_seed_4_tlab_model.pt\"\n",
    "SEED = int(test_weight_file.split(\"_\")[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "from train import train\n",
    "from val import validate\n",
    "from test import Test\n",
    "from utils.parser import parse_configuration\n",
    "import numpy as np\n",
    "from models.orig_cam import TLAB_CAM as Custom_CAModel\n",
    "from models.tsav import TwoStreamAuralVisualModel\n",
    "from datasets.dataset_val import ImageList_val\n",
    "from losses.loss import CCCLoss\n",
    "from datetime import datetime\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with xavier\n",
      "Saved cammodel_accV :  0.6718117677052116\n",
      "Saved cammodel_accA :  0.5835919757541999\n",
      "Number of Sequences: 83\n"
     ]
    }
   ],
   "source": [
    "TrainingAccuracy_V = []\n",
    "TrainingAccuracy_A = []\n",
    "ValidationAccuracy_V = []\n",
    "ValidationAccuracy_A = []\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "\n",
    "class ValPadSequence:\n",
    "\tdef __call__(self, sorted_batch):\n",
    "\n",
    "\t\tsequences = [x[0] for x in sorted_batch]\n",
    "\t\taud_sequences = [x[1] for x in sorted_batch]\n",
    "\t\tspec_dim = []\n",
    "\t\tfor aud in aud_sequences:\n",
    "\t\t\tspec_dim.append(aud.shape[3])\n",
    "\n",
    "\t\tmax_spec_dim = max(spec_dim)\n",
    "\t\taudio_features = torch.zeros(len(spec_dim), 16, 1, 64, max_spec_dim)\n",
    "\t\tfor batch_idx, spectrogram in enumerate(aud_sequences):\n",
    "\t\t\tif spectrogram.shape[2] < max_spec_dim:\n",
    "\t\t\t\taudio_features[batch_idx, :, :, :, -spectrogram.shape[3]:] = spectrogram\n",
    "\t\t\telse:\n",
    "\t\t\t\taudio_features[batch_idx, :,:, :, :] = spectrogram\n",
    "\n",
    "\t\tframeids = [x[2] for x in sorted_batch]\n",
    "\t\tv_ids = [x[3] for x in sorted_batch]\n",
    "\t\tv_lengths = [x[4] for x in sorted_batch]\n",
    "\t\tlabelV = [x[5] for x in sorted_batch]\n",
    "\t\tlabelA = [x[6] for x in sorted_batch]\n",
    "\n",
    "\t\tvisual_sequences = torch.stack(sequences)\n",
    "\t\tlabelsV = torch.stack(labelV)\n",
    "\t\tlabelsA = torch.stack(labelA)\n",
    "\t\treturn visual_sequences, audio_features, frameids, v_ids, v_lengths, labelsV, labelsA\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_path = 'ABAW2020TNT/model2/TSAV_Sub4_544k.pth.tar' # path to the model\n",
    "model = TwoStreamAuralVisualModel(num_channels=4)\n",
    "saved_model = torch.load(model_path)\n",
    "model.load_state_dict(saved_model['state_dict'])\n",
    "\n",
    "new_first_layer = nn.Conv3d(in_channels=3,\n",
    "\t\t\t\t\tout_channels=model.video_model.r2plus1d.stem[0].out_channels,\n",
    "\t\t\t\t\tkernel_size=model.video_model.r2plus1d.stem[0].kernel_size,\n",
    "\t\t\t\t\tstride=model.video_model.r2plus1d.stem[0].stride,\n",
    "\t\t\t\t\tpadding=model.video_model.r2plus1d.stem[0].padding,\n",
    "\t\t\t\t\tbias=False)\n",
    "\n",
    "new_first_layer.weight.data = model.video_model.r2plus1d.stem[0].weight.data[:, 0:3]\n",
    "model.video_model.r2plus1d.stem[0] = new_first_layer\n",
    "model = nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "\n",
    "### Freezing the model\n",
    "for p in model.parameters():\n",
    "\tp.requires_grad = False\n",
    "for p in model.children():\n",
    "\tp.train(False)\n",
    " \n",
    "fusion_model = Custom_CAModel()\n",
    "# fusion_model = nn.DataParallel(fusion_model)\n",
    "# fusion_model.cuda()\n",
    "fusion_model = fusion_model.to(device=device)\n",
    "\n",
    "cam_model_path = f'SavedWeights/{test_weight_file}' # path to the model\n",
    "cam_saved_model = torch.load(cam_model_path)\n",
    "fusion_model.load_state_dict(cam_saved_model['net'])\n",
    "cammodel_accV = torch.load(cam_model_path)['best_Val_accV']\n",
    "cammodel_accA = torch.load(cam_model_path)['best_Val_accA']\n",
    "print(\"Saved cammodel_accV : \", cammodel_accV)\n",
    "print(\"Saved cammodel_accA : \", cammodel_accA)\n",
    "for param in fusion_model.parameters():  # children():\n",
    "    param.requires_grad = False\n",
    "\n",
    "config = \"config_file.json\"\n",
    "configuration = parse_configuration(config)\n",
    "\n",
    "dataset_rootpath = configuration['dataset_rootpath']\n",
    "dataset_wavspath = configuration['dataset_wavspath']\n",
    "dataset_labelpath = configuration['labelpath']\n",
    "\n",
    "def load_partition_set(partition_path, seed):\n",
    "\timport json\n",
    "\n",
    "\twith open(partition_path, 'r') as f:    \n",
    "\t\tseed_data = json.load(f)\n",
    "\n",
    "\tseed_data_train = seed_data[f'seed_{seed}']['Train_Set']\n",
    "\tseed_data_valid = seed_data[f'seed_{seed}']['Validation_Set']\n",
    "\tseed_data_test  = seed_data[f'seed_{seed}']['Test_Set']\n",
    " \n",
    "\tseed_data_train = [fn + \".csv\" for fn in seed_data_train]\n",
    "\tseed_data_valid = [fn + \".csv\" for fn in seed_data_valid]\n",
    "\tseed_data_test  = [fn + \".csv\" for fn in seed_data_test ]\n",
    "\n",
    "\treturn seed_data_train, seed_data_valid, seed_data_test\n",
    "\n",
    "partition_path = \"../data/Affwild2/seed_data.json\"\n",
    "train_set, valid_set, test_set = load_partition_set(partition_path, SEED)\n",
    "\n",
    "init_time = datetime.now()\n",
    "init_time = init_time.strftime('%m%d_%H%M')\n",
    "\n",
    "criterion = CCCLoss(digitize_num=1).cuda()\n",
    "\n",
    "testdataset = ImageList_val(root=configuration['dataset_rootpath'], fileList=test_set, labelPath=dataset_labelpath,\n",
    "\t\t\t\t\taudList=configuration['dataset_wavspath'], length=configuration['test_params']['seq_length'],\n",
    "\t\t\t\t\tflag='Test', stride=configuration['test_params']['stride'], dilation = configuration['test_params']['dilation'],\n",
    "\t\t\t\t\tsubseq_length = configuration['test_params']['subseq_length'])\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "\t\t\ttestdataset, collate_fn=ValPadSequence(),\n",
    "\t\t\t**configuration['test_params']['loader_params'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "import numpy as np\n",
    "import sys\n",
    "from EvaluationMetrics.cccmetric import ccc\n",
    "\n",
    "\n",
    "def Test(val_loader, model, criterion, cam):\n",
    "    # switch to evaluate mode\n",
    "    global Val_acc\n",
    "    global best_Val_acc\n",
    "    global best_Val_acc_epoch\n",
    "    #model.eval()\n",
    "    model.eval()\n",
    "    cam.eval()\n",
    "\n",
    "    vout = []\n",
    "    vtar = []\n",
    "    aout = []\n",
    "    atar = []\n",
    "\t#torch.cuda.synchronize()\n",
    "    #t7 = time.time()\n",
    "    pred_a = dict()\n",
    "    pred_v = dict()\n",
    "    label_a = dict()\n",
    "    label_v = dict()\n",
    "\t#files_dict = {}\n",
    "    count = 0\n",
    "    \n",
    "    vid_pred = {}\n",
    "    vid_label = {}\n",
    "    vid_ccc = {}\n",
    "    global_vid_fts, global_aud_fts= None, None\n",
    "    \n",
    "    for batch_idx, (visualdata, audiodata, frame_ids, videos, vid_lengths, labelsV, labelsA) in tqdm(enumerate(val_loader),\n",
    "                                                            total=len(val_loader), position=0, leave=True):\n",
    "        \n",
    "        audiodata = audiodata.cuda()#.unsqueeze(2)\n",
    "        visualdata = visualdata.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            b, seq_t, c, subseq_t, h, w = visualdata.size()\n",
    "            visual_feats = torch.empty((b, seq_t, 25088), dtype=visualdata.dtype, device = visualdata.device)\n",
    "            aud_feats = torch.empty((b, seq_t, 512), dtype=visualdata.dtype, device = visualdata.device)\n",
    "            for i in range(visualdata.shape[0]):\n",
    "                audio_feat, visualfeat, _ = model(audiodata[i,:,:,:], visualdata[i, :, :, :,:,:])\n",
    "                visual_feats[i,:,:] = visualfeat\n",
    "                aud_feats[i,:,:] = audio_feat\n",
    "\n",
    "            audiovisual_vouts,audiovisual_aouts = cam(aud_feats, visual_feats)\n",
    "\n",
    "            audiovisual_vouts = audiovisual_vouts.detach().cpu().numpy()\n",
    "            audiovisual_aouts = audiovisual_aouts.detach().cpu().numpy()\n",
    "\n",
    "            labelsV = labelsV.cpu().numpy()\n",
    "            labelsA = labelsA.cpu().numpy()\n",
    "\n",
    "            for voutputs, aoutputs, labelV, labelA, frameids, video, vid_length in zip(audiovisual_vouts, audiovisual_aouts, labelsV, labelsA, frame_ids, videos, vid_lengths):\n",
    "                for voutput, aoutput, labV, labA, frameid, vid, length in zip(voutputs, aoutputs, labelV, labelA, frameids, video, vid_length):\n",
    "                    if vid not in pred_a:\n",
    "                        if frameid>1:\n",
    "                            print(vid)\n",
    "                            print(length)\n",
    "                            print(\"something is wrong\")\n",
    "                            sys.exit()\n",
    "                        count = count + 1\n",
    "\n",
    "                        pred_a[vid] = [0]*length\n",
    "                        pred_v[vid] = [0]*length\n",
    "                        label_a[vid] = [0]*length\n",
    "                        label_v[vid] = [0]*length\n",
    "                        if labV == -5.0:\n",
    "                            continue\n",
    "                        pred_a[vid][frameid-1] = aoutput\n",
    "                        pred_v[vid][frameid-1] = voutput\n",
    "                        label_a[vid][frameid-1] = labA\n",
    "                        label_v[vid][frameid-1] = labV\n",
    "                    else:\n",
    "                        if frameid <= length:\n",
    "                            if labV == -5.0:\n",
    "                                continue\n",
    "                            pred_a[vid][frameid-1] = aoutput\n",
    "                            pred_v[vid][frameid-1] = voutput\n",
    "                            label_a[vid][frameid-1] = labA\n",
    "                            label_v[vid][frameid-1] = labV\n",
    "                            \n",
    "\n",
    "    for idx, key in enumerate(pred_a.keys()):\n",
    "        clipped_preds_v = np.clip(pred_v[key], -1.0, 1.0)\n",
    "        clipped_preds_a = np.clip(pred_a[key], -1.0, 1.0)\n",
    "\n",
    "        smoothened_preds_v = uniform_filter1d(clipped_preds_v, size=20, mode='constant')\n",
    "        smoothened_preds_a = uniform_filter1d(clipped_preds_a, size=50, mode='constant')\n",
    "        tars_v = label_v[key]\n",
    "        tars_a = label_a[key]\n",
    "        \n",
    "        key_vout = []\n",
    "        key_aout = []\n",
    "        key_vtar = []\n",
    "        key_atar = []\n",
    "\n",
    "        for i in range(len(smoothened_preds_a)):\n",
    "            vout.append(smoothened_preds_v[i])\n",
    "            aout.append(smoothened_preds_a[i])\n",
    "            vtar.append(tars_v[i])\n",
    "            atar.append(tars_a[i])\n",
    "            \n",
    "            key_vout.append(smoothened_preds_v[i])\n",
    "            key_aout.append(smoothened_preds_a[i])\n",
    "            key_vtar.append(tars_v[i])\n",
    "            key_atar.append(tars_a[i])\n",
    "                \n",
    "        vid_pred[key] = {\"vout\": type(key_vout), \"aout\": type(key_aout)}\n",
    "        vid_label[key] = {\"vtar\": type(key_vtar), \"atar\": type(key_atar)}\n",
    "        vid_ccc[key] = {\"vccc\": 0, \"accc\": 0}\n",
    "\n",
    "        vid_pred[key][\"vout\"] = key_vout\n",
    "        vid_pred[key][\"aout\"] = key_aout\n",
    "        vid_label[key][\"vtar\"] = key_vtar\n",
    "        vid_label[key][\"atar\"] = key_atar\n",
    "        vid_ccc[key]['vccc'] = ccc(np.array(key_vout), np.array(key_vtar))\n",
    "        vid_ccc[key]['accc'] = ccc(np.array(key_aout), np.array(key_atar))\n",
    "        \n",
    "\n",
    "    accV = ccc(np.array(vout), np.array(vtar))\n",
    "    accA = ccc(np.array(aout), np.array(atar))\n",
    "\n",
    "    print(accV)\n",
    "    print(accA)\n",
    "    return accV, accA, vid_pred, vid_label, vid_ccc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Test samples:25093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1569/1569 [2:10:24<00:00,  4.99s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6472975391225876\n",
      "0.5953760915680057\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Test samples:\" + str(len(testdataset)))\n",
    "Test_vacc, Test_aacc, vid_pred, vid_label, vid_ccc = Test(testloader, model, criterion, fusion_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'182': [0.7716025948812367, 0.686247714300239, 0.7289251545907378],\n",
       " '364': [0.48137348833799215, 0.4105269697539261, 0.44595022904595916],\n",
       " '69-25-854x480': [0.6846254395006239, 0.629211213542568, 0.656918326521596],\n",
       " '345': [0.12502731927457986, 0.08172516942804298, 0.10337624435131142],\n",
       " '228': [0.6617028006731703, 0.5431162258656882, 0.6024095132694293],\n",
       " '46-30-484x360_left': [0.5479894344704841,\n",
       "  0.35712218114151384,\n",
       "  0.45255580780599897],\n",
       " '216': [0.07418898077748412, 0.591043074953709, 0.3326160278655966],\n",
       " '140': [0.5209846682465135, 0.5802792277125954, 0.5506319479795545],\n",
       " '153': [0.5802972440275991, 0.6338727105350905, 0.6070849772813448],\n",
       " '240': [0.4045469026581872, 0.4229250681401068, 0.413735985399147],\n",
       " '5-60-1920x1080-4': [0.3663811537888009,\n",
       "  0.5366388549317861,\n",
       "  0.4515100043602935],\n",
       " '412': [0.40464192162999985, 0.00532326127765154, 0.2049825914538257],\n",
       " '308': [0.08373699197876855, 0.413853439577607, 0.24879521577818778],\n",
       " '137': [0.10633990370483704, 0.47946021832503843, 0.2929000610149377],\n",
       " '279': [0.35331863523475965, 0.04752307183750926, 0.20042085353613445],\n",
       " '94-30-1920x1080': [0.2046846187310659,\n",
       "  -0.0504986408609512,\n",
       "  0.07709298893505734],\n",
       " '210': [0.38067892228680755, 0.6175180563919407, 0.4990984893393741],\n",
       " '47-30-654x480': [0.30307690758867156,\n",
       "  0.48135173913133245,\n",
       "  0.392214323360002],\n",
       " '319': [0.5993957761120393, 0.6851115455514051, 0.6422536608317222],\n",
       " '235': [0.08674036528798139, 0.29745824438667046, 0.19209930483732593],\n",
       " '110-30-270x480': [0.17943551748192177,\n",
       "  0.022799099123667316,\n",
       "  0.10111730830279454],\n",
       " '186': [0.20822578865171124, 0.7192683078363605, 0.4637470482440359],\n",
       " '90-30-1080x1920': [0.2720625485126841,\n",
       "  0.5165224483364588,\n",
       "  0.3942924984245714],\n",
       " '317': [0.6950841628882252, 0.7008276858326774, 0.6979559243604513],\n",
       " '385': [0.34188319449554627, 0.3492263593361673, 0.3455547769158568],\n",
       " '41-24-1280x720': [0.2006778768505246,\n",
       "  0.43163274545847985,\n",
       "  0.31615531115450224],\n",
       " '384': [0.0882269971342674, 0.48712003673215254, 0.28767351693320997],\n",
       " '120': [0.45953288530492714, 0.4024463683523423, 0.43098962682863473],\n",
       " '335': [0.1555617534948948, 0.6770056307483661, 0.4162836921216304],\n",
       " '395': [0.5089693724896226, 0.2735522125142053, 0.3912607925019139],\n",
       " '23-24-1920x1080': [0.17789626222354177,\n",
       "  0.3451790745595052,\n",
       "  0.2615376683915235],\n",
       " '326': [0.305715736704462, 0.41455878746933933, 0.36013726208690067],\n",
       " '227': [0.5483960627823969, 0.7295444759289685, 0.6389702693556827],\n",
       " '46-30-484x360_right': [0.41912918795483545,\n",
       "  0.4481502808683725,\n",
       "  0.43363973441160397],\n",
       " '131': [0.4000514031742977, 0.5989898310844467, 0.49952061712937224],\n",
       " '185': [0.7280110775913582, 0.6761211066125661, 0.7020660921019621],\n",
       " '106-30-720x1280': [0.5679931071124403,\n",
       "  0.5275599678323718,\n",
       "  0.5477765374724061],\n",
       " '163': [0.5275410989088171, 0.4437814682915991, 0.4856612836002081],\n",
       " '114': [0.5336350163134225, 0.20040311424805216, 0.3670190652807373],\n",
       " '198': [0.05065327445342999, 0.5508915653840554, 0.3007724199187427],\n",
       " '28-30-1280x720-1': [0.7703653445908296,\n",
       "  0.6762164429882402,\n",
       "  0.7232908937895349],\n",
       " '213': [0.13818406666670396, 0.2915851818867995, 0.21488462427675173],\n",
       " '28-30-1280x720-3': [0.5803007207879608,\n",
       "  0.6126171206686515,\n",
       "  0.5964589207283062],\n",
       " '320': [0.6262089852462291, 0.5272756302907727, 0.576742307768501],\n",
       " '151': [0.3393266160043539, 0.3259268485941157, 0.3326267322992348],\n",
       " '298': [0.6287306991626573, 0.5359566105293215, 0.5823436548459895],\n",
       " '447': [-0.18968908581732158, 0.46692614699440355, 0.13861853058854098],\n",
       " '135-24-1920x1080_right': [0.5759516039962392,\n",
       "  0.21507597607656512,\n",
       "  0.3955137900364022],\n",
       " '100-29-1080x1920': [0.5245417749380149,\n",
       "  0.4830790045744625,\n",
       "  0.5038103897562387],\n",
       " '427': [0.8731696211786798, 0.7063598879855747, 0.7897647545821272],\n",
       " '107': [0.6071652861903757, 0.3061498017647909, 0.4566575439775833],\n",
       " '39-25-424x240': [0.5989682928134475, 0.8241118670299454, 0.7115400799216964],\n",
       " '126': [0.5562391446362958, 0.4577079109190515, 0.5069735277776737],\n",
       " '346': [0.2006117810975838, 0.2317702258133529, 0.21619100345546835],\n",
       " '368': [0.031198704331756703, 0.2644352475823211, 0.1478169759570389],\n",
       " '435': [0.5001425416803309, 0.3194862351763447, 0.40981438842833784],\n",
       " '149': [0.27129827425593483, 0.3870685673411105, 0.3291834207985227],\n",
       " '129': [0.07243835794480671, 0.46095664701503686, 0.2666975024799218],\n",
       " '15-24-1920x1080': [0.11014511735242082,\n",
       "  0.2542602282160329,\n",
       "  0.18220267278422686],\n",
       " '24-30-1920x1080-1': [0.532430860579391,\n",
       "  0.3968011758377626,\n",
       "  0.4646160182085768],\n",
       " '92-24-1920x1080': [0.7733924390482395,\n",
       "  0.6702319436687717,\n",
       "  0.7218121913585056],\n",
       " '136-30-1920x1080': [0.4082514593446208,\n",
       "  0.44506788321934637,\n",
       "  0.42665967128198357],\n",
       " '101-30-1080x1920': [0.45633972378985693,\n",
       "  0.12449266798373822,\n",
       "  0.29041619588679757],\n",
       " '363': [0.4743467583141757, 0.4949442967220468, 0.4846455275181113],\n",
       " '440': [0.8519322985451514, 0.506700387883116, 0.6793163432141337],\n",
       " '327': [0.09802424906353474, 0.49130792902732007, 0.2946660890454274],\n",
       " 'video59_right': [0.6292110027624469, 0.2933137133508041, 0.4612623580566255],\n",
       " 'video62': [0.21276196327183156, 0.21250764655053944, 0.2126348049111855],\n",
       " 'video85': [0.027610552806558743, 0.19423728318215758, 0.11092391799435816],\n",
       " '107-30-640x480': [-0.08017629666533016,\n",
       "  0.3625469784216216,\n",
       "  0.14118534087814572],\n",
       " 'video66': [0.11005202305147513, 0.3031798231382148, 0.20661592309484494],\n",
       " '1-30-1280x720': [0.25336840554625145,\n",
       "  0.19511405775753832,\n",
       "  0.22424123165189488],\n",
       " 'video55_left': [0.0022460359027825093,\n",
       "  0.16888289925624408,\n",
       "  0.0855644675795133],\n",
       " 'video59': [0.3139537891865136, 0.31326506644670965, 0.3136094278166116],\n",
       " 'video93': [0.002568896060145906, 0.01458943266519112, 0.008579164362668514],\n",
       " '113-60-1280x720': [-0.023330020941724688,\n",
       "  0.13596334307971505,\n",
       "  0.05631666106899518],\n",
       " '21-24-1920x1080': [0.8144059161107636,\n",
       "  0.37664196802495087,\n",
       "  0.5955239420678573],\n",
       " 'video70': [0.39197579843715796, 0.6214737654886551, 0.5067247819629065],\n",
       " 'video94': [0.1574007942739168, 0.12105725083124529, 0.13922902255258104],\n",
       " 'video64': [0.27075286033670326, 0.24891375335774152, 0.2598333068472224],\n",
       " 'video74_right': [0.5838280899268948, 0.6297809938369943, 0.6068045418819445],\n",
       " 'video61': [0.5383200880125615, 0.4300757230675958, 0.48419790554007863],\n",
       " 'video58': [nan, nan, nan]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ccc_result = {} # {\"vi FF FFd\" : [valence, arousal, mean]}\n",
    "for k in vid_ccc.keys():\n",
    "    new_ccc_result[k] = [vid_ccc[k]['vccc'], vid_ccc[k]['accc'], np.mean([vid_ccc[k]['vccc'], vid_ccc[k]['accc']])]\n",
    "    \n",
    "new_ccc_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('video93',\n",
       "  [0.002568896060145906, 0.01458943266519112, 0.008579164362668514]),\n",
       " ('113-60-1280x720',\n",
       "  [-0.023330020941724688, 0.13596334307971505, 0.05631666106899518]),\n",
       " ('94-30-1920x1080',\n",
       "  [0.2046846187310659, -0.0504986408609512, 0.07709298893505734]),\n",
       " ('video55_left',\n",
       "  [0.0022460359027825093, 0.16888289925624408, 0.0855644675795133]),\n",
       " ('110-30-270x480',\n",
       "  [0.17943551748192177, 0.022799099123667316, 0.10111730830279454]),\n",
       " ('345', [0.12502731927457986, 0.08172516942804298, 0.10337624435131142]),\n",
       " ('video85', [0.027610552806558743, 0.19423728318215758, 0.11092391799435816]),\n",
       " ('447', [-0.18968908581732158, 0.46692614699440355, 0.13861853058854098]),\n",
       " ('video94', [0.1574007942739168, 0.12105725083124529, 0.13922902255258104]),\n",
       " ('107-30-640x480',\n",
       "  [-0.08017629666533016, 0.3625469784216216, 0.14118534087814572]),\n",
       " ('368', [0.031198704331756703, 0.2644352475823211, 0.1478169759570389]),\n",
       " ('15-24-1920x1080',\n",
       "  [0.11014511735242082, 0.2542602282160329, 0.18220267278422686]),\n",
       " ('235', [0.08674036528798139, 0.29745824438667046, 0.19209930483732593]),\n",
       " ('279', [0.35331863523475965, 0.04752307183750926, 0.20042085353613445]),\n",
       " ('412', [0.40464192162999985, 0.00532326127765154, 0.2049825914538257]),\n",
       " ('video66', [0.11005202305147513, 0.3031798231382148, 0.20661592309484494]),\n",
       " ('video62', [0.21276196327183156, 0.21250764655053944, 0.2126348049111855]),\n",
       " ('213', [0.13818406666670396, 0.2915851818867995, 0.21488462427675173]),\n",
       " ('346', [0.2006117810975838, 0.2317702258133529, 0.21619100345546835]),\n",
       " ('1-30-1280x720',\n",
       "  [0.25336840554625145, 0.19511405775753832, 0.22424123165189488]),\n",
       " ('308', [0.08373699197876855, 0.413853439577607, 0.24879521577818778]),\n",
       " ('video64', [0.27075286033670326, 0.24891375335774152, 0.2598333068472224]),\n",
       " ('23-24-1920x1080',\n",
       "  [0.17789626222354177, 0.3451790745595052, 0.2615376683915235]),\n",
       " ('129', [0.07243835794480671, 0.46095664701503686, 0.2666975024799218]),\n",
       " ('384', [0.0882269971342674, 0.48712003673215254, 0.28767351693320997]),\n",
       " ('101-30-1080x1920',\n",
       "  [0.45633972378985693, 0.12449266798373822, 0.29041619588679757]),\n",
       " ('137', [0.10633990370483704, 0.47946021832503843, 0.2929000610149377]),\n",
       " ('327', [0.09802424906353474, 0.49130792902732007, 0.2946660890454274]),\n",
       " ('198', [0.05065327445342999, 0.5508915653840554, 0.3007724199187427]),\n",
       " ('video59', [0.3139537891865136, 0.31326506644670965, 0.3136094278166116]),\n",
       " ('41-24-1280x720',\n",
       "  [0.2006778768505246, 0.43163274545847985, 0.31615531115450224]),\n",
       " ('149', [0.27129827425593483, 0.3870685673411105, 0.3291834207985227]),\n",
       " ('216', [0.07418898077748412, 0.591043074953709, 0.3326160278655966]),\n",
       " ('151', [0.3393266160043539, 0.3259268485941157, 0.3326267322992348]),\n",
       " ('385', [0.34188319449554627, 0.3492263593361673, 0.3455547769158568]),\n",
       " ('326', [0.305715736704462, 0.41455878746933933, 0.36013726208690067]),\n",
       " ('114', [0.5336350163134225, 0.20040311424805216, 0.3670190652807373]),\n",
       " ('395', [0.5089693724896226, 0.2735522125142053, 0.3912607925019139]),\n",
       " ('47-30-654x480',\n",
       "  [0.30307690758867156, 0.48135173913133245, 0.392214323360002]),\n",
       " ('90-30-1080x1920',\n",
       "  [0.2720625485126841, 0.5165224483364588, 0.3942924984245714]),\n",
       " ('135-24-1920x1080_right',\n",
       "  [0.5759516039962392, 0.21507597607656512, 0.3955137900364022]),\n",
       " ('435', [0.5001425416803309, 0.3194862351763447, 0.40981438842833784]),\n",
       " ('240', [0.4045469026581872, 0.4229250681401068, 0.413735985399147]),\n",
       " ('335', [0.1555617534948948, 0.6770056307483661, 0.4162836921216304]),\n",
       " ('136-30-1920x1080',\n",
       "  [0.4082514593446208, 0.44506788321934637, 0.42665967128198357]),\n",
       " ('120', [0.45953288530492714, 0.4024463683523423, 0.43098962682863473]),\n",
       " ('46-30-484x360_right',\n",
       "  [0.41912918795483545, 0.4481502808683725, 0.43363973441160397]),\n",
       " ('364', [0.48137348833799215, 0.4105269697539261, 0.44595022904595916]),\n",
       " ('5-60-1920x1080-4',\n",
       "  [0.3663811537888009, 0.5366388549317861, 0.4515100043602935]),\n",
       " ('46-30-484x360_left',\n",
       "  [0.5479894344704841, 0.35712218114151384, 0.45255580780599897]),\n",
       " ('107', [0.6071652861903757, 0.3061498017647909, 0.4566575439775833]),\n",
       " ('video59_right',\n",
       "  [0.6292110027624469, 0.2933137133508041, 0.4612623580566255]),\n",
       " ('186', [0.20822578865171124, 0.7192683078363605, 0.4637470482440359]),\n",
       " ('24-30-1920x1080-1',\n",
       "  [0.532430860579391, 0.3968011758377626, 0.4646160182085768]),\n",
       " ('video61', [0.5383200880125615, 0.4300757230675958, 0.48419790554007863]),\n",
       " ('363', [0.4743467583141757, 0.4949442967220468, 0.4846455275181113]),\n",
       " ('163', [0.5275410989088171, 0.4437814682915991, 0.4856612836002081]),\n",
       " ('210', [0.38067892228680755, 0.6175180563919407, 0.4990984893393741]),\n",
       " ('131', [0.4000514031742977, 0.5989898310844467, 0.49952061712937224]),\n",
       " ('100-29-1080x1920',\n",
       "  [0.5245417749380149, 0.4830790045744625, 0.5038103897562387]),\n",
       " ('video70', [0.39197579843715796, 0.6214737654886551, 0.5067247819629065]),\n",
       " ('126', [0.5562391446362958, 0.4577079109190515, 0.5069735277776737]),\n",
       " ('106-30-720x1280',\n",
       "  [0.5679931071124403, 0.5275599678323718, 0.5477765374724061]),\n",
       " ('140', [0.5209846682465135, 0.5802792277125954, 0.5506319479795545]),\n",
       " ('320', [0.6262089852462291, 0.5272756302907727, 0.576742307768501]),\n",
       " ('298', [0.6287306991626573, 0.5359566105293215, 0.5823436548459895]),\n",
       " ('21-24-1920x1080',\n",
       "  [0.8144059161107636, 0.37664196802495087, 0.5955239420678573]),\n",
       " ('28-30-1280x720-3',\n",
       "  [0.5803007207879608, 0.6126171206686515, 0.5964589207283062]),\n",
       " ('228', [0.6617028006731703, 0.5431162258656882, 0.6024095132694293]),\n",
       " ('video74_right',\n",
       "  [0.5838280899268948, 0.6297809938369943, 0.6068045418819445]),\n",
       " ('153', [0.5802972440275991, 0.6338727105350905, 0.6070849772813448]),\n",
       " ('227', [0.5483960627823969, 0.7295444759289685, 0.6389702693556827]),\n",
       " ('319', [0.5993957761120393, 0.6851115455514051, 0.6422536608317222]),\n",
       " ('69-25-854x480', [0.6846254395006239, 0.629211213542568, 0.656918326521596]),\n",
       " ('440', [0.8519322985451514, 0.506700387883116, 0.6793163432141337]),\n",
       " ('317', [0.6950841628882252, 0.7008276858326774, 0.6979559243604513]),\n",
       " ('185', [0.7280110775913582, 0.6761211066125661, 0.7020660921019621]),\n",
       " ('39-25-424x240',\n",
       "  [0.5989682928134475, 0.8241118670299454, 0.7115400799216964]),\n",
       " ('92-24-1920x1080',\n",
       "  [0.7733924390482395, 0.6702319436687717, 0.7218121913585056]),\n",
       " ('28-30-1280x720-1',\n",
       "  [0.7703653445908296, 0.6762164429882402, 0.7232908937895349]),\n",
       " ('182', [0.7716025948812367, 0.686247714300239, 0.7289251545907378]),\n",
       " ('427', [0.8731696211786798, 0.7063598879855747, 0.7897647545821272]),\n",
       " ('video58', [nan, nan, nan])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_vid = sorted(new_ccc_result.items(), key=lambda x: x[1][2])\n",
    "sort_vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import openpyxl\n",
    "\n",
    "xl_dir_path = \"xl_dir\"\n",
    "if not os.path.exists(xl_dir_path):\n",
    "    os.makedirs(xl_dir_path)\n",
    "\n",
    "columns = [\"file_name\", \"infer_val\", \"infer_aro\", \"infer_mean\", \"anno_val\", \"anno_aro\", \"anno_mean\"]\n",
    "file_values_dict = {c:[] for c in columns}\n",
    "\n",
    "columns = list(file_values_dict.keys())\n",
    "orig_label = vid_label\n",
    "\n",
    "for vid,score_list in sort_vid:\n",
    "    file_values_dict['file_name'].append(vid)\n",
    "    \n",
    "    file_values_dict['infer_val'].append(np.round(score_list[0], 3))\n",
    "    file_values_dict['infer_aro'].append(np.round(score_list[1], 3))\n",
    "    file_values_dict['infer_mean'].append(np.round(score_list[2], 3))\n",
    "    \n",
    "    \n",
    "    orig_label_arousal = np.mean(orig_label[vid]['atar'])\n",
    "    orig_label_valence = np.mean(orig_label[vid]['vtar'])\n",
    "    \n",
    "    file_values_dict['anno_val'].append(np.round(orig_label_arousal, 3))\n",
    "    file_values_dict['anno_aro'].append(np.round(orig_label_valence, 3))\n",
    "    \n",
    "    orig_label_mean = np.mean([orig_label_arousal, orig_label_valence])\n",
    "    file_values_dict['anno_mean'].append(np.round(orig_label_mean, 3))    \n",
    "    \n",
    "    \n",
    "xl_file_name = f\"gat_self_score_csv_file_{SEED}.xlsx\"\n",
    "xl_file = os.path.join(xl_dir_path, xl_file_name)\n",
    "\n",
    "if not os.path.exists(xl_file):\n",
    "    wb=openpyxl.Workbook()\n",
    "    wb.save(xl_file)\n",
    "    \n",
    "full_record_df = pd.DataFrame(file_values_dict, columns=columns) # todo    \n",
    "    \n",
    "# full_records 시트를 작성하여 파일을 생성\n",
    "with pd.ExcelWriter(xl_file, mode='w', engine='openpyxl') as writer:\n",
    "    full_record_df.to_excel(writer, sheet_name=\"full_records\", index=False, encoding='utf-8')\n",
    "    \n",
    "with pd.ExcelWriter(xl_file, mode='a', engine='openpyxl') as writer:\n",
    "    for vid, scores in sort_vid:\n",
    "        va_df_dict = {\n",
    "            \"pred_val\" : [],\n",
    "            \"pred_aro\" : [],\n",
    "            \"label_val\" : [],\n",
    "            \"label_aro\" : []\n",
    "        }\n",
    "        va_df_dict[\"pred_val\"].extend(vid_pred[vid]['vout'])\n",
    "        va_df_dict[\"pred_aro\"].extend(vid_pred[vid]['aout'])\n",
    "        va_df_dict[\"label_val\"].extend(vid_label[vid]['vtar'])\n",
    "        va_df_dict[\"label_aro\"].extend(vid_label[vid]['atar'])\n",
    "        \n",
    "        va_df = pd.DataFrame(va_df_dict, columns=va_df_dict.keys())\n",
    "        va_df.to_excel(writer, sheet_name=vid, index=False)\n",
    "        \n",
    "    writer.save()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = \"save/results/gat_self_overall_results_ccc.csv\"\n",
    "record_v, record_a, record_m = f\"{Test_vacc:.3f}\", f\"{Test_aacc:.3f}\", f\"{np.mean([Test_vacc, Test_aacc]):.3f}\"\n",
    "\n",
    "result_col = [\"seed\", \"Valence_ccc\", \"Arousal_ccc\", \"Mean_CCC\"]\n",
    "record = [SEED, record_v, record_a, record_m]\n",
    "\n",
    "df = pd.DataFrame([record], columns=result_col)\n",
    "if not os.path.exists(result_path):\n",
    "    df.to_csv(result_path, index=False)\n",
    "else:\n",
    "    df.to_csv(result_path, mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set에 대한 최종 표준편차까지 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>Valence_ccc</th>\n",
       "      <th>Arousal_ccc</th>\n",
       "      <th>Mean_CCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seed  Valence_ccc  Arousal_ccc  Mean_CCC\n",
       "0   0.0        0.625        0.569     0.597\n",
       "1   1.0        0.625        0.617     0.621\n",
       "2   2.0        0.602        0.573     0.587\n",
       "3   4.0        0.647        0.595     0.621"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>Valence_ccc</th>\n",
       "      <th>Arousal_ccc</th>\n",
       "      <th>Mean_CCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  seed Valence_ccc Arousal_ccc Mean_CCC\n",
       "0    0       0.625       0.569    0.597\n",
       "1    1       0.625       0.617    0.621\n",
       "2    2       0.602       0.573    0.587\n",
       "3    4       0.647       0.595    0.621"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_path = \"save/results/gat_self_overall_results_ccc.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "data = data[~(data['seed'] == \"result\")]\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "for k in data:\n",
    "    data[k] = data[k].astype(np.float32)\n",
    "\n",
    "display(data)\n",
    "\n",
    "res = {}\n",
    "res['seed'] = \"result\"\n",
    "res['Valence_ccc']  = f\"{np.mean(data['Valence_ccc']):.3f} ± {np.std(data['Valence_ccc']):.3f}\"\n",
    "res['Arousal_ccc']  = f\"{np.mean(data['Arousal_ccc']):.3f} ± {np.std(data['Arousal_ccc']):.3f}\"\n",
    "res['Mean_CCC']     = f\"{np.mean(data['Mean_CCC']):.3f} ± {np.std(data['Mean_CCC']):.3f}\"\n",
    "\n",
    "\n",
    "data['seed'] = data['seed'].apply(lambda x : f\"{x:.0f}\")\n",
    "data['Valence_ccc'] = data['Valence_ccc'].apply(lambda x : f\"{x:.3f}\")\n",
    "data['Arousal_ccc'] = data['Arousal_ccc'].apply(lambda x : f\"{x:.3f}\")\n",
    "data['Mean_CCC'] = data['Mean_CCC'].apply(lambda x : f\"{x:.3f}\")\n",
    "\n",
    "display(data)\n",
    "\n",
    "data = data.append(res, ignore_index=True)\n",
    "data.to_csv(data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Load the Excel file\n",
    "# file_path22 = 'xl_dir/paper3_score_csv_file_0_nan387.xlsx'\n",
    "\n",
    "# # Load the 'full_records' sheet\n",
    "# old_data = pd.read_excel(file_path22, sheet_name='full_records')\n",
    "\n",
    "# # Display the first few rows of the dataframe to understand its structure\n",
    "# old_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# data = old_data[~((old_data['file_name'] == '387') & (old_data['file_name'] == '389'))]\n",
    "# np.mean(data.loc[:, ['infer_val', 'infer_aro', 'infer_mean']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Multimodal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
