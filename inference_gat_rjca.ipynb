{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실행 순서\n",
    "\n",
    "1. 1셀 test_weight_file 필요한 시드 웨이트 파일로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "test_weight_file = \"0126_1628_seed_0_tlab_model.pt\"\n",
    "SEED = int(test_weight_file.split(\"_\")[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "from train import train\n",
    "from val import validate\n",
    "from test import Test\n",
    "from utils.parser import parse_configuration\n",
    "import numpy as np\n",
    "from models.orig_cam import TLAB_CAM as Custom_CAModel\n",
    "from models.tsav import TwoStreamAuralVisualModel\n",
    "from datasets.dataset_val import ImageList_val\n",
    "from losses.loss import CCCLoss\n",
    "from datetime import datetime\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with xavier\n",
      "Saved cammodel_accV :  0.6246879650361636\n",
      "Saved cammodel_accA :  0.609533512707734\n",
      "Number of Sequences: 83\n"
     ]
    }
   ],
   "source": [
    "TrainingAccuracy_V = []\n",
    "TrainingAccuracy_A = []\n",
    "ValidationAccuracy_V = []\n",
    "ValidationAccuracy_A = []\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "\n",
    "class ValPadSequence:\n",
    "\tdef __call__(self, sorted_batch):\n",
    "\n",
    "\t\tsequences = [x[0] for x in sorted_batch]\n",
    "\t\taud_sequences = [x[1] for x in sorted_batch]\n",
    "\t\tspec_dim = []\n",
    "\t\tfor aud in aud_sequences:\n",
    "\t\t\tspec_dim.append(aud.shape[3])\n",
    "\n",
    "\t\tmax_spec_dim = max(spec_dim)\n",
    "\t\taudio_features = torch.zeros(len(spec_dim), 16, 1, 64, max_spec_dim)\n",
    "\t\tfor batch_idx, spectrogram in enumerate(aud_sequences):\n",
    "\t\t\tif spectrogram.shape[2] < max_spec_dim:\n",
    "\t\t\t\taudio_features[batch_idx, :, :, :, -spectrogram.shape[3]:] = spectrogram\n",
    "\t\t\telse:\n",
    "\t\t\t\taudio_features[batch_idx, :,:, :, :] = spectrogram\n",
    "\n",
    "\t\tframeids = [x[2] for x in sorted_batch]\n",
    "\t\tv_ids = [x[3] for x in sorted_batch]\n",
    "\t\tv_lengths = [x[4] for x in sorted_batch]\n",
    "\t\tlabelV = [x[5] for x in sorted_batch]\n",
    "\t\tlabelA = [x[6] for x in sorted_batch]\n",
    "\n",
    "\t\tvisual_sequences = torch.stack(sequences)\n",
    "\t\tlabelsV = torch.stack(labelV)\n",
    "\t\tlabelsA = torch.stack(labelA)\n",
    "\t\treturn visual_sequences, audio_features, frameids, v_ids, v_lengths, labelsV, labelsA\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_path = 'ABAW2020TNT/model2/TSAV_Sub4_544k.pth.tar' # path to the model\n",
    "model = TwoStreamAuralVisualModel(num_channels=4)\n",
    "saved_model = torch.load(model_path)\n",
    "model.load_state_dict(saved_model['state_dict'])\n",
    "\n",
    "new_first_layer = nn.Conv3d(in_channels=3,\n",
    "\t\t\t\t\tout_channels=model.video_model.r2plus1d.stem[0].out_channels,\n",
    "\t\t\t\t\tkernel_size=model.video_model.r2plus1d.stem[0].kernel_size,\n",
    "\t\t\t\t\tstride=model.video_model.r2plus1d.stem[0].stride,\n",
    "\t\t\t\t\tpadding=model.video_model.r2plus1d.stem[0].padding,\n",
    "\t\t\t\t\tbias=False)\n",
    "\n",
    "new_first_layer.weight.data = model.video_model.r2plus1d.stem[0].weight.data[:, 0:3]\n",
    "model.video_model.r2plus1d.stem[0] = new_first_layer\n",
    "model = nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "\n",
    "### Freezing the model\n",
    "for p in model.parameters():\n",
    "\tp.requires_grad = False\n",
    "for p in model.children():\n",
    "\tp.train(False)\n",
    " \n",
    "fusion_model = Custom_CAModel()\n",
    "# fusion_model = nn.DataParallel(fusion_model)\n",
    "# fusion_model.cuda()\n",
    "fusion_model = fusion_model.to(device=device)\n",
    "\n",
    "cam_model_path = f'SavedWeights/{test_weight_file}' # path to the model\n",
    "cam_saved_model = torch.load(cam_model_path)\n",
    "fusion_model.load_state_dict(cam_saved_model['net'])\n",
    "cammodel_accV = torch.load(cam_model_path)['best_Val_accV']\n",
    "cammodel_accA = torch.load(cam_model_path)['best_Val_accA']\n",
    "print(\"Saved cammodel_accV : \", cammodel_accV)\n",
    "print(\"Saved cammodel_accA : \", cammodel_accA)\n",
    "for param in fusion_model.parameters():  # children():\n",
    "    param.requires_grad = False\n",
    "\n",
    "config = \"config_file.json\"\n",
    "configuration = parse_configuration(config)\n",
    "\n",
    "dataset_rootpath = configuration['dataset_rootpath']\n",
    "dataset_wavspath = configuration['dataset_wavspath']\n",
    "dataset_labelpath = configuration['labelpath']\n",
    "\n",
    "def load_partition_set(partition_path, seed):\n",
    "\timport json\n",
    "\n",
    "\twith open(partition_path, 'r') as f:    \n",
    "\t\tseed_data = json.load(f)\n",
    "\n",
    "\tseed_data_train = seed_data[f'seed_{seed}']['Train_Set']\n",
    "\tseed_data_valid = seed_data[f'seed_{seed}']['Validation_Set']\n",
    "\tseed_data_test  = seed_data[f'seed_{seed}']['Test_Set']\n",
    " \n",
    "\tseed_data_train = [fn + \".csv\" for fn in seed_data_train]\n",
    "\tseed_data_valid = [fn + \".csv\" for fn in seed_data_valid]\n",
    "\tseed_data_test  = [fn + \".csv\" for fn in seed_data_test ]\n",
    "\n",
    "\treturn seed_data_train, seed_data_valid, seed_data_test\n",
    "\n",
    "partition_path = \"../data/Affwild2/seed_data.json\"\n",
    "train_set, valid_set, test_set = load_partition_set(partition_path, SEED)\n",
    "\n",
    "init_time = datetime.now()\n",
    "init_time = init_time.strftime('%m%d_%H%M')\n",
    "\n",
    "criterion = CCCLoss(digitize_num=1).cuda()\n",
    "\n",
    "testdataset = ImageList_val(root=configuration['dataset_rootpath'], fileList=test_set, labelPath=dataset_labelpath,\n",
    "\t\t\t\t\taudList=configuration['dataset_wavspath'], length=configuration['test_params']['seq_length'],\n",
    "\t\t\t\t\tflag='Test', stride=configuration['test_params']['stride'], dilation = configuration['test_params']['dilation'],\n",
    "\t\t\t\t\tsubseq_length = configuration['test_params']['subseq_length'])\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "\t\t\ttestdataset, collate_fn=ValPadSequence(),\n",
    "\t\t\t**configuration['test_params']['loader_params'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "import numpy as np\n",
    "import sys\n",
    "from EvaluationMetrics.cccmetric import ccc\n",
    "\n",
    "\n",
    "def Test(val_loader, model, criterion, cam):\n",
    "    # switch to evaluate mode\n",
    "    global Val_acc\n",
    "    global best_Val_acc\n",
    "    global best_Val_acc_epoch\n",
    "    #model.eval()\n",
    "    model.eval()\n",
    "    cam.eval()\n",
    "\n",
    "    vout = []\n",
    "    vtar = []\n",
    "    aout = []\n",
    "    atar = []\n",
    "\t#torch.cuda.synchronize()\n",
    "    #t7 = time.time()\n",
    "    pred_a = dict()\n",
    "    pred_v = dict()\n",
    "    label_a = dict()\n",
    "    label_v = dict()\n",
    "\t#files_dict = {}\n",
    "    count = 0\n",
    "    \n",
    "    vid_pred = {}\n",
    "    vid_label = {}\n",
    "    vid_ccc = {}\n",
    "    global_vid_fts, global_aud_fts= None, None\n",
    "    \n",
    "    for batch_idx, (visualdata, audiodata, frame_ids, videos, vid_lengths, labelsV, labelsA) in tqdm(enumerate(val_loader),\n",
    "                                                            total=len(val_loader), position=0, leave=True):\n",
    "        \n",
    "        audiodata = audiodata.cuda()#.unsqueeze(2)\n",
    "        visualdata = visualdata.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            b, seq_t, c, subseq_t, h, w = visualdata.size()\n",
    "            visual_feats = torch.empty((b, seq_t, 25088), dtype=visualdata.dtype, device = visualdata.device)\n",
    "            aud_feats = torch.empty((b, seq_t, 512), dtype=visualdata.dtype, device = visualdata.device)\n",
    "            for i in range(visualdata.shape[0]):\n",
    "                audio_feat, visualfeat, _ = model(audiodata[i,:,:,:], visualdata[i, :, :, :,:,:])\n",
    "                visual_feats[i,:,:] = visualfeat\n",
    "                aud_feats[i,:,:] = audio_feat\n",
    "\n",
    "            audiovisual_vouts,audiovisual_aouts = cam(aud_feats, visual_feats)\n",
    "\n",
    "            audiovisual_vouts = audiovisual_vouts.detach().cpu().numpy()\n",
    "            audiovisual_aouts = audiovisual_aouts.detach().cpu().numpy()\n",
    "\n",
    "            labelsV = labelsV.cpu().numpy()\n",
    "            labelsA = labelsA.cpu().numpy()\n",
    "\n",
    "            for voutputs, aoutputs, labelV, labelA, frameids, video, vid_length in zip(audiovisual_vouts, audiovisual_aouts, labelsV, labelsA, frame_ids, videos, vid_lengths):\n",
    "                for voutput, aoutput, labV, labA, frameid, vid, length in zip(voutputs, aoutputs, labelV, labelA, frameids, video, vid_length):\n",
    "                    if vid not in pred_a:\n",
    "                        if frameid>1:\n",
    "                            print(vid)\n",
    "                            print(length)\n",
    "                            print(\"something is wrong\")\n",
    "                            sys.exit()\n",
    "                        count = count + 1\n",
    "\n",
    "                        pred_a[vid] = [0]*length\n",
    "                        pred_v[vid] = [0]*length\n",
    "                        label_a[vid] = [0]*length\n",
    "                        label_v[vid] = [0]*length\n",
    "                        if labV == -5.0:\n",
    "                            continue\n",
    "                        pred_a[vid][frameid-1] = aoutput\n",
    "                        pred_v[vid][frameid-1] = voutput\n",
    "                        label_a[vid][frameid-1] = labA\n",
    "                        label_v[vid][frameid-1] = labV\n",
    "                    else:\n",
    "                        if frameid <= length:\n",
    "                            if labV == -5.0:\n",
    "                                continue\n",
    "                            pred_a[vid][frameid-1] = aoutput\n",
    "                            pred_v[vid][frameid-1] = voutput\n",
    "                            label_a[vid][frameid-1] = labA\n",
    "                            label_v[vid][frameid-1] = labV\n",
    "                            \n",
    "\n",
    "    for idx, key in enumerate(pred_a.keys()):\n",
    "        clipped_preds_v = np.clip(pred_v[key], -1.0, 1.0)\n",
    "        clipped_preds_a = np.clip(pred_a[key], -1.0, 1.0)\n",
    "\n",
    "        smoothened_preds_v = uniform_filter1d(clipped_preds_v, size=20, mode='constant')\n",
    "        smoothened_preds_a = uniform_filter1d(clipped_preds_a, size=50, mode='constant')\n",
    "        tars_v = label_v[key]\n",
    "        tars_a = label_a[key]\n",
    "        \n",
    "        key_vout = []\n",
    "        key_aout = []\n",
    "        key_vtar = []\n",
    "        key_atar = []\n",
    "\n",
    "        for i in range(len(smoothened_preds_a)):\n",
    "            vout.append(smoothened_preds_v[i])\n",
    "            aout.append(smoothened_preds_a[i])\n",
    "            vtar.append(tars_v[i])\n",
    "            atar.append(tars_a[i])\n",
    "            \n",
    "            key_vout.append(smoothened_preds_v[i])\n",
    "            key_aout.append(smoothened_preds_a[i])\n",
    "            key_vtar.append(tars_v[i])\n",
    "            key_atar.append(tars_a[i])\n",
    "                \n",
    "        vid_pred[key] = {\"vout\": type(key_vout), \"aout\": type(key_aout)}\n",
    "        vid_label[key] = {\"vtar\": type(key_vtar), \"atar\": type(key_atar)}\n",
    "        vid_ccc[key] = {\"vccc\": 0, \"accc\": 0}\n",
    "\n",
    "        vid_pred[key][\"vout\"] = key_vout\n",
    "        vid_pred[key][\"aout\"] = key_aout\n",
    "        vid_label[key][\"vtar\"] = key_vtar\n",
    "        vid_label[key][\"atar\"] = key_atar\n",
    "        vid_ccc[key]['vccc'] = ccc(np.array(key_vout), np.array(key_vtar))\n",
    "        vid_ccc[key]['accc'] = ccc(np.array(key_aout), np.array(key_atar))\n",
    "        \n",
    "\n",
    "    accV = ccc(np.array(vout), np.array(vtar))\n",
    "    accA = ccc(np.array(aout), np.array(atar))\n",
    "\n",
    "    print(accV)\n",
    "    print(accA)\n",
    "    return accV, accA, vid_pred, vid_label, vid_ccc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Test samples:22048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1378/1378 [1:43:36<00:00,  4.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6018237380765902\n",
      "0.5761364691168872\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Test samples:\" + str(len(testdataset)))\n",
    "Test_vacc, Test_aacc, vid_pred, vid_label, vid_ccc = Test(testloader, model, criterion, fusion_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'211': [-0.07262394527845151, 0.256982839277211, 0.09217944699937974],\n",
       " '203': [0.1528944037887368, 0.5121113265687993, 0.33250286517876804],\n",
       " '325': [0.4565397779189026, 0.5656755163064809, 0.5111076471126917],\n",
       " '290': [0.5853654452920659, 0.4934554004655243, 0.539410422878795],\n",
       " '117-25-1920x1080': [0.38141316567909495,\n",
       "  0.2642286690121335,\n",
       "  0.32282091734561424],\n",
       " '123': [0.4269492932887261, 0.6631905546126232, 0.5450699239506747],\n",
       " '99-30-720x720': [0.7373197166467725,\n",
       "  0.25666600459895084,\n",
       "  0.4969928606228617],\n",
       " '46-30-484x360_left': [0.5339969276625177,\n",
       "  0.5312816120102796,\n",
       "  0.5326392698363986],\n",
       " '252': [0.6131513472574194, 0.6857433928501679, 0.6494473700537937],\n",
       " '140': [0.5710902108642422, 0.676556851777371, 0.6238235313208066],\n",
       " '51-30-1280x720': [-0.029055419141702305,\n",
       "  0.45253757911314757,\n",
       "  0.21174107998572264],\n",
       " '425': [0.5959955564427697, 0.7246061836270032, 0.6603008700348865],\n",
       " '288': [0.7027302934493633, 0.5770611144921779, 0.6398957039707707],\n",
       " '28-30-1280x720-4': [0.7314923213914004,\n",
       "  0.47262214584637613,\n",
       "  0.6020572336188883],\n",
       " '94-30-1920x1080': [0.27470370593419485,\n",
       "  -0.0442029668833234,\n",
       "  0.11525036952543573],\n",
       " '387': [0.3437680266580086, 0.14365059135683247, 0.24370930900742055],\n",
       " '210': [0.516871271895805, 0.6451679405213192, 0.5810196062085621],\n",
       " '181': [0.3863194217503588, 0.30720993901188903, 0.34676468038112396],\n",
       " '214': [-0.05742048754643841, 0.3258419230218001, 0.13421071773768084],\n",
       " '421': [0.6787201818577316, 0.31947182396851653, 0.49909600291312406],\n",
       " '150': [0.0345331616340343, 0.3641307675625104, 0.19933196459827235],\n",
       " '392': [0.028180120613132485, 0.33154210774741405, 0.17986111418027326],\n",
       " '398': [0.7833114331005735, 0.6730782362458176, 0.7281948346731956],\n",
       " '146': [0.5445256096022736, 0.3123023742169358, 0.4284139919096047],\n",
       " '202': [0.5084566141730736, 0.71251458941056, 0.6104856017918168],\n",
       " '110-30-270x480': [0.23563685349436042,\n",
       "  0.04646611814395569,\n",
       "  0.14105148581915805],\n",
       " '17-24-1920x1080': [0.2057969971521289,\n",
       "  0.16336228013077422,\n",
       "  0.18457963864145155],\n",
       " '428': [0.7075017212267577, 0.7328286762182222, 0.72016519872249],\n",
       " '120': [0.4245601704656812, 0.4924352990932722, 0.4584977347794767],\n",
       " '61-24-1920x1080': [0.5478575346373583,\n",
       "  0.4662317911923936,\n",
       "  0.5070446629148759],\n",
       " '223': [0.25074622394846136, 0.19367811614594924, 0.22221217004720528],\n",
       " '154': [0.3275225143721576, 0.6213392764914287, 0.4744308954317932],\n",
       " '185': [0.6730688189598498, 0.7332579876355966, 0.7031634032977232],\n",
       " '189': [0.69767724175427, 0.6788049763561472, 0.6882411090552086],\n",
       " '377': [0.6162167132503498, 0.5115004975364105, 0.5638586053933801],\n",
       " '328': [0.2868183215722341, 0.6292883078776884, 0.45805331472496125],\n",
       " '45-24-1280x720': [0.6913223976574706,\n",
       "  0.7244833281395678,\n",
       "  0.7079028628985192],\n",
       " '114': [0.4888233719348083, 0.3415845118665936, 0.415203941900701],\n",
       " '143': [0.3231395314781389, 0.37375872354803014, 0.34844912751308454],\n",
       " '68-24-1920x1080': [0.3788962039993661,\n",
       "  0.38113770739082653,\n",
       "  0.3800169556950963],\n",
       " '296': [0.17707704464004106, 0.486424876270469, 0.33175096045525504],\n",
       " '196': [0.38302830336263205, 0.5323580738439657, 0.4576931886032989],\n",
       " '98-30-360x360': [0.11805736688627258,\n",
       "  0.04756056282699024,\n",
       "  0.08280896485663142],\n",
       " '447': [-0.10940963097814013, 0.5151911421169932, 0.20289075556942654],\n",
       " '388': [-0.05410805127688569, 0.03017797132961105, -0.01196503997363732],\n",
       " '246': [0.905078731059844, 0.7740080950059447, 0.8395434130328944],\n",
       " '107': [0.23977039897242255, 0.401547978115701, 0.3206591885440618],\n",
       " '65-30-400x228': [0.6866155491776792, 0.6117126685613887, 0.6491641088695339],\n",
       " '184': [0.48607723623557486, 0.8123831763382753, 0.6492302062869251],\n",
       " '141': [0.35063844971097546, 0.4696703118283749, 0.41015438076967514],\n",
       " '126': [0.3883861666620293, 0.36623330236937224, 0.37730973451570077],\n",
       " '134': [0.467765426525253, 0.6277234147820304, 0.5477444206536417],\n",
       " '50-30-1920x1080': [0.04647612243568451,\n",
       "  -0.01210870882393434,\n",
       "  0.017183706805875085],\n",
       " '341': [0.6249688259222986, 0.6122220604920876, 0.6185954432071932],\n",
       " '5-60-1920x1080-3': [0.5559575097360925,\n",
       "  0.6673171497783442,\n",
       "  0.6116373297572184],\n",
       " '149': [0.3848712988230963, 0.5365696663273917, 0.460720482575244],\n",
       " '89-30-1080x1920': [0.471415921987086,\n",
       "  0.5912751900284492,\n",
       "  0.5313455560077676],\n",
       " '179': [0.3942395431453722, 0.37401398558251625, 0.3841267643639442],\n",
       " '293': [0.7441405254216271, 0.40988529451940137, 0.5770129099705142],\n",
       " '15-24-1920x1080': [0.27542202845241254,\n",
       "  0.35521711680663653,\n",
       "  0.31531957262952454],\n",
       " '389': [0.6560570441362576, 0.1301577962869438, 0.3931074202116007],\n",
       " '24-30-1920x1080-1': [0.449685545557998,\n",
       "  0.4173578937783216,\n",
       "  0.4335217196681598],\n",
       " '78-30-960x720': [0.37132535770585373,\n",
       "  0.7125824739808777,\n",
       "  0.5419539158433657],\n",
       " '258': [0.42116873430858526, 0.6207326680429083, 0.5209507011757468],\n",
       " '363': [0.5976115125613256, 0.6803790674060249, 0.6389952899836753],\n",
       " '264': [0.41985322628572086, 0.20383325945766603, 0.31184324287169346],\n",
       " '440': [0.8176927962474249, 0.49635415249245973, 0.6570234743699424],\n",
       " '327': [-0.04817349527870539, 0.5542059314418389, 0.25301621808156677],\n",
       " 'video86_3': [0.5708262721781969, 0.5130970008002568, 0.5419616364892268],\n",
       " 'video80': [-0.019414952226841812, 0.4234584527434035, 0.20202175025828084],\n",
       " 'video75': [0.6008618858362851, 0.2967579360410354, 0.44880991093866024],\n",
       " 'video66': [0.00696769078266363, 0.023719526601373987, 0.015343608692018808],\n",
       " 'video76': [0.5616564093767905, 0.33824990297447294, 0.4499531561756317],\n",
       " '25-25-600x480': [0.33062208884012406,\n",
       "  0.6165100468816116,\n",
       "  0.47356606786086786],\n",
       " '79-30-960x720': [0.3476415198821023,\n",
       "  0.32066320520904357,\n",
       "  0.3341523625455729],\n",
       " 'video55_left': [0.1728322840070765, 0.2814545346971956, 0.22714340935213606],\n",
       " 'video83': [0.25804617336600455, 0.17693956467131455, 0.21749286901865955],\n",
       " '76-30-640x280': [-0.03424851630201494,\n",
       "  0.3909960853222859,\n",
       "  0.1783737845101355],\n",
       " '16-30-1920x1080': [0.7791963194445235,\n",
       "  0.33685039456310234,\n",
       "  0.5580233570038129],\n",
       " 'video84': [0.8439553733961205, 0.7354317117169149, 0.7896935425565177],\n",
       " 'video61': [0.4577315129818882, 0.28056126429877215, 0.36914638864033017],\n",
       " '118-30-640x480': [0.09341191158082747,\n",
       "  0.2118150211580163,\n",
       "  0.15261346636942189],\n",
       " 'video89': [-0.03629786536045985, 0.324485959814897, 0.14409404722721855]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ccc_result = {} # {\"vi FF FFd\" : [valence, arousal, mean]}\n",
    "for k in vid_ccc.keys():\n",
    "    new_ccc_result[k] = [vid_ccc[k]['vccc'], vid_ccc[k]['accc'], np.mean([vid_ccc[k]['vccc'], vid_ccc[k]['accc']])]\n",
    "    \n",
    "new_ccc_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('388', [-0.05410805127688569, 0.03017797132961105, -0.01196503997363732]),\n",
       " ('video66',\n",
       "  [0.00696769078266363, 0.023719526601373987, 0.015343608692018808]),\n",
       " ('50-30-1920x1080',\n",
       "  [0.04647612243568451, -0.01210870882393434, 0.017183706805875085]),\n",
       " ('98-30-360x360',\n",
       "  [0.11805736688627258, 0.04756056282699024, 0.08280896485663142]),\n",
       " ('211', [-0.07262394527845151, 0.256982839277211, 0.09217944699937974]),\n",
       " ('94-30-1920x1080',\n",
       "  [0.27470370593419485, -0.0442029668833234, 0.11525036952543573]),\n",
       " ('214', [-0.05742048754643841, 0.3258419230218001, 0.13421071773768084]),\n",
       " ('110-30-270x480',\n",
       "  [0.23563685349436042, 0.04646611814395569, 0.14105148581915805]),\n",
       " ('video89', [-0.03629786536045985, 0.324485959814897, 0.14409404722721855]),\n",
       " ('118-30-640x480',\n",
       "  [0.09341191158082747, 0.2118150211580163, 0.15261346636942189]),\n",
       " ('76-30-640x280',\n",
       "  [-0.03424851630201494, 0.3909960853222859, 0.1783737845101355]),\n",
       " ('392', [0.028180120613132485, 0.33154210774741405, 0.17986111418027326]),\n",
       " ('17-24-1920x1080',\n",
       "  [0.2057969971521289, 0.16336228013077422, 0.18457963864145155]),\n",
       " ('150', [0.0345331616340343, 0.3641307675625104, 0.19933196459827235]),\n",
       " ('video80', [-0.019414952226841812, 0.4234584527434035, 0.20202175025828084]),\n",
       " ('447', [-0.10940963097814013, 0.5151911421169932, 0.20289075556942654]),\n",
       " ('51-30-1280x720',\n",
       "  [-0.029055419141702305, 0.45253757911314757, 0.21174107998572264]),\n",
       " ('video83', [0.25804617336600455, 0.17693956467131455, 0.21749286901865955]),\n",
       " ('223', [0.25074622394846136, 0.19367811614594924, 0.22221217004720528]),\n",
       " ('video55_left',\n",
       "  [0.1728322840070765, 0.2814545346971956, 0.22714340935213606]),\n",
       " ('387', [0.3437680266580086, 0.14365059135683247, 0.24370930900742055]),\n",
       " ('327', [-0.04817349527870539, 0.5542059314418389, 0.25301621808156677]),\n",
       " ('264', [0.41985322628572086, 0.20383325945766603, 0.31184324287169346]),\n",
       " ('15-24-1920x1080',\n",
       "  [0.27542202845241254, 0.35521711680663653, 0.31531957262952454]),\n",
       " ('107', [0.23977039897242255, 0.401547978115701, 0.3206591885440618]),\n",
       " ('117-25-1920x1080',\n",
       "  [0.38141316567909495, 0.2642286690121335, 0.32282091734561424]),\n",
       " ('296', [0.17707704464004106, 0.486424876270469, 0.33175096045525504]),\n",
       " ('203', [0.1528944037887368, 0.5121113265687993, 0.33250286517876804]),\n",
       " ('79-30-960x720',\n",
       "  [0.3476415198821023, 0.32066320520904357, 0.3341523625455729]),\n",
       " ('181', [0.3863194217503588, 0.30720993901188903, 0.34676468038112396]),\n",
       " ('143', [0.3231395314781389, 0.37375872354803014, 0.34844912751308454]),\n",
       " ('video61', [0.4577315129818882, 0.28056126429877215, 0.36914638864033017]),\n",
       " ('126', [0.3883861666620293, 0.36623330236937224, 0.37730973451570077]),\n",
       " ('68-24-1920x1080',\n",
       "  [0.3788962039993661, 0.38113770739082653, 0.3800169556950963]),\n",
       " ('179', [0.3942395431453722, 0.37401398558251625, 0.3841267643639442]),\n",
       " ('389', [0.6560570441362576, 0.1301577962869438, 0.3931074202116007]),\n",
       " ('141', [0.35063844971097546, 0.4696703118283749, 0.41015438076967514]),\n",
       " ('114', [0.4888233719348083, 0.3415845118665936, 0.415203941900701]),\n",
       " ('146', [0.5445256096022736, 0.3123023742169358, 0.4284139919096047]),\n",
       " ('24-30-1920x1080-1',\n",
       "  [0.449685545557998, 0.4173578937783216, 0.4335217196681598]),\n",
       " ('video75', [0.6008618858362851, 0.2967579360410354, 0.44880991093866024]),\n",
       " ('video76', [0.5616564093767905, 0.33824990297447294, 0.4499531561756317]),\n",
       " ('196', [0.38302830336263205, 0.5323580738439657, 0.4576931886032989]),\n",
       " ('328', [0.2868183215722341, 0.6292883078776884, 0.45805331472496125]),\n",
       " ('120', [0.4245601704656812, 0.4924352990932722, 0.4584977347794767]),\n",
       " ('149', [0.3848712988230963, 0.5365696663273917, 0.460720482575244]),\n",
       " ('25-25-600x480',\n",
       "  [0.33062208884012406, 0.6165100468816116, 0.47356606786086786]),\n",
       " ('154', [0.3275225143721576, 0.6213392764914287, 0.4744308954317932]),\n",
       " ('99-30-720x720',\n",
       "  [0.7373197166467725, 0.25666600459895084, 0.4969928606228617]),\n",
       " ('421', [0.6787201818577316, 0.31947182396851653, 0.49909600291312406]),\n",
       " ('61-24-1920x1080',\n",
       "  [0.5478575346373583, 0.4662317911923936, 0.5070446629148759]),\n",
       " ('325', [0.4565397779189026, 0.5656755163064809, 0.5111076471126917]),\n",
       " ('258', [0.42116873430858526, 0.6207326680429083, 0.5209507011757468]),\n",
       " ('89-30-1080x1920',\n",
       "  [0.471415921987086, 0.5912751900284492, 0.5313455560077676]),\n",
       " ('46-30-484x360_left',\n",
       "  [0.5339969276625177, 0.5312816120102796, 0.5326392698363986]),\n",
       " ('290', [0.5853654452920659, 0.4934554004655243, 0.539410422878795]),\n",
       " ('78-30-960x720',\n",
       "  [0.37132535770585373, 0.7125824739808777, 0.5419539158433657]),\n",
       " ('video86_3', [0.5708262721781969, 0.5130970008002568, 0.5419616364892268]),\n",
       " ('123', [0.4269492932887261, 0.6631905546126232, 0.5450699239506747]),\n",
       " ('134', [0.467765426525253, 0.6277234147820304, 0.5477444206536417]),\n",
       " ('16-30-1920x1080',\n",
       "  [0.7791963194445235, 0.33685039456310234, 0.5580233570038129]),\n",
       " ('377', [0.6162167132503498, 0.5115004975364105, 0.5638586053933801]),\n",
       " ('293', [0.7441405254216271, 0.40988529451940137, 0.5770129099705142]),\n",
       " ('210', [0.516871271895805, 0.6451679405213192, 0.5810196062085621]),\n",
       " ('28-30-1280x720-4',\n",
       "  [0.7314923213914004, 0.47262214584637613, 0.6020572336188883]),\n",
       " ('202', [0.5084566141730736, 0.71251458941056, 0.6104856017918168]),\n",
       " ('5-60-1920x1080-3',\n",
       "  [0.5559575097360925, 0.6673171497783442, 0.6116373297572184]),\n",
       " ('341', [0.6249688259222986, 0.6122220604920876, 0.6185954432071932]),\n",
       " ('140', [0.5710902108642422, 0.676556851777371, 0.6238235313208066]),\n",
       " ('363', [0.5976115125613256, 0.6803790674060249, 0.6389952899836753]),\n",
       " ('288', [0.7027302934493633, 0.5770611144921779, 0.6398957039707707]),\n",
       " ('65-30-400x228',\n",
       "  [0.6866155491776792, 0.6117126685613887, 0.6491641088695339]),\n",
       " ('184', [0.48607723623557486, 0.8123831763382753, 0.6492302062869251]),\n",
       " ('252', [0.6131513472574194, 0.6857433928501679, 0.6494473700537937]),\n",
       " ('440', [0.8176927962474249, 0.49635415249245973, 0.6570234743699424]),\n",
       " ('425', [0.5959955564427697, 0.7246061836270032, 0.6603008700348865]),\n",
       " ('189', [0.69767724175427, 0.6788049763561472, 0.6882411090552086]),\n",
       " ('185', [0.6730688189598498, 0.7332579876355966, 0.7031634032977232]),\n",
       " ('45-24-1280x720',\n",
       "  [0.6913223976574706, 0.7244833281395678, 0.7079028628985192]),\n",
       " ('428', [0.7075017212267577, 0.7328286762182222, 0.72016519872249]),\n",
       " ('398', [0.7833114331005735, 0.6730782362458176, 0.7281948346731956]),\n",
       " ('video84', [0.8439553733961205, 0.7354317117169149, 0.7896935425565177]),\n",
       " ('246', [0.905078731059844, 0.7740080950059447, 0.8395434130328944])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_vid = sorted(new_ccc_result.items(), key=lambda x: x[1][2])\n",
    "sort_vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import openpyxl\n",
    "\n",
    "xl_dir_path = \"xl_dir\"\n",
    "if not os.path.exists(xl_dir_path):\n",
    "    os.makedirs(xl_dir_path)\n",
    "\n",
    "columns = [\"file_name\", \"infer_val\", \"infer_aro\", \"infer_mean\", \"anno_val\", \"anno_aro\", \"anno_mean\"]\n",
    "file_values_dict = {c:[] for c in columns}\n",
    "\n",
    "columns = list(file_values_dict.keys())\n",
    "orig_label = vid_label\n",
    "\n",
    "for vid,score_list in sort_vid:\n",
    "    file_values_dict['file_name'].append(vid)\n",
    "    \n",
    "    file_values_dict['infer_val'].append(np.round(score_list[0], 3))\n",
    "    file_values_dict['infer_aro'].append(np.round(score_list[1], 3))\n",
    "    file_values_dict['infer_mean'].append(np.round(score_list[2], 3))\n",
    "    \n",
    "    \n",
    "    orig_label_arousal = np.mean(orig_label[vid]['atar'])\n",
    "    orig_label_valence = np.mean(orig_label[vid]['vtar'])\n",
    "    \n",
    "    file_values_dict['anno_val'].append(np.round(orig_label_arousal, 3))\n",
    "    file_values_dict['anno_aro'].append(np.round(orig_label_valence, 3))\n",
    "    \n",
    "    orig_label_mean = np.mean([orig_label_arousal, orig_label_valence])\n",
    "    file_values_dict['anno_mean'].append(np.round(orig_label_mean, 3))    \n",
    "    \n",
    "    \n",
    "xl_file_name = f\"tlab_score_csv_file_{SEED}.xlsx\"\n",
    "xl_file = os.path.join(xl_dir_path, xl_file_name)\n",
    "\n",
    "if not os.path.exists(xl_file):\n",
    "    wb=openpyxl.Workbook()\n",
    "    wb.save(xl_file)\n",
    "    \n",
    "full_record_df = pd.DataFrame(file_values_dict, columns=columns) # todo    \n",
    "    \n",
    "# full_records 시트를 작성하여 파일을 생성\n",
    "with pd.ExcelWriter(xl_file, mode='w', engine='openpyxl') as writer:\n",
    "    full_record_df.to_excel(writer, sheet_name=\"full_records\", index=False, encoding='utf-8')\n",
    "    \n",
    "with pd.ExcelWriter(xl_file, mode='a', engine='openpyxl') as writer:\n",
    "    for vid, scores in sort_vid:\n",
    "        va_df_dict = {\n",
    "            \"pred_val\" : [],\n",
    "            \"pred_aro\" : [],\n",
    "            \"label_val\" : [],\n",
    "            \"label_aro\" : []\n",
    "        }\n",
    "        va_df_dict[\"pred_val\"].extend(vid_pred[vid]['vout'])\n",
    "        va_df_dict[\"pred_aro\"].extend(vid_pred[vid]['aout'])\n",
    "        va_df_dict[\"label_val\"].extend(vid_label[vid]['vtar'])\n",
    "        va_df_dict[\"label_aro\"].extend(vid_label[vid]['atar'])\n",
    "        \n",
    "        va_df = pd.DataFrame(va_df_dict, columns=va_df_dict.keys())\n",
    "        va_df.to_excel(writer, sheet_name=vid, index=False)\n",
    "        \n",
    "    writer.save()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = \"save/results/tlab_overall_results_ccc.csv\"\n",
    "record_v, record_a, record_m = f\"{Test_vacc:.3f}\", f\"{Test_aacc:.3f}\", f\"{np.mean([Test_vacc, Test_aacc]):.3f}\"\n",
    "\n",
    "result_col = [\"seed\", \"Valence_ccc\", \"Arousal_ccc\", \"Mean_CCC\"]\n",
    "record = [SEED, record_v, record_a, record_m]\n",
    "\n",
    "df = pd.DataFrame([record], columns=result_col)\n",
    "if not os.path.exists(result_path):\n",
    "    df.to_csv(result_path, index=False)\n",
    "else:\n",
    "    df.to_csv(result_path, mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set에 대한 최종 표준편차까지 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>Valence_ccc</th>\n",
       "      <th>Arousal_ccc</th>\n",
       "      <th>Mean_CCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seed  Valence_ccc  Arousal_ccc  Mean_CCC\n",
       "0   0.0        0.602        0.576     0.589"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>Valence_ccc</th>\n",
       "      <th>Arousal_ccc</th>\n",
       "      <th>Mean_CCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  seed Valence_ccc Arousal_ccc Mean_CCC\n",
       "0    0       0.602       0.576    0.589"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_path = \"save/results/tlab_overall_results_ccc.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "data = data[~(data['seed'] == \"result\")]\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "for k in data:\n",
    "    data[k] = data[k].astype(np.float32)\n",
    "\n",
    "display(data)\n",
    "\n",
    "res = {}\n",
    "res['seed'] = \"result\"\n",
    "res['Valence_ccc']  = f\"{np.mean(data['Valence_ccc']):.3f} ± {np.std(data['Valence_ccc']):.3f}\"\n",
    "res['Arousal_ccc']  = f\"{np.mean(data['Arousal_ccc']):.3f} ± {np.std(data['Arousal_ccc']):.3f}\"\n",
    "res['Mean_CCC']     = f\"{np.mean(data['Mean_CCC']):.3f} ± {np.std(data['Mean_CCC']):.3f}\"\n",
    "\n",
    "\n",
    "data['seed'] = data['seed'].apply(lambda x : f\"{x:.0f}\")\n",
    "data['Valence_ccc'] = data['Valence_ccc'].apply(lambda x : f\"{x:.3f}\")\n",
    "data['Arousal_ccc'] = data['Arousal_ccc'].apply(lambda x : f\"{x:.3f}\")\n",
    "data['Mean_CCC'] = data['Mean_CCC'].apply(lambda x : f\"{x:.3f}\")\n",
    "\n",
    "display(data)\n",
    "\n",
    "data = data.append(res, ignore_index=True)\n",
    "data.to_csv(data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Load the Excel file\n",
    "# file_path22 = 'xl_dir/paper3_score_csv_file_0_nan387.xlsx'\n",
    "\n",
    "# # Load the 'full_records' sheet\n",
    "# old_data = pd.read_excel(file_path22, sheet_name='full_records')\n",
    "\n",
    "# # Display the first few rows of the dataframe to understand its structure\n",
    "# old_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# data = old_data[~((old_data['file_name'] == '387') & (old_data['file_name'] == '389'))]\n",
    "# np.mean(data.loc[:, ['infer_val', 'infer_aro', 'infer_mean']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Multimodal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
