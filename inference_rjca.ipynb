{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실행 순서\n",
    "\n",
    "1. 1셀 test_weight_file 필요한 시드 웨이트 파일로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "test_weight_file = \"0819_1845_seed_4_orig_lstm_model.pt\"\n",
    "SEED = int(test_weight_file.split(\"_\")[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "from train import train\n",
    "from val import validate\n",
    "from test import Test\n",
    "from utils.parser import parse_configuration\n",
    "import numpy as np\n",
    "from models.orig_cam import LSTM_CAM\n",
    "from models.tsav import TwoStreamAuralVisualModel\n",
    "from datasets.dataset_val import ImageList_val\n",
    "from losses.loss import CCCLoss\n",
    "from datetime import datetime\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with xavier\n",
      "Saved cammodel_accV :  0.4105292724554147\n",
      "Saved cammodel_accA :  0.5499361618391662\n",
      "Number of Sequences: 83\n"
     ]
    }
   ],
   "source": [
    "TrainingAccuracy_V = []\n",
    "TrainingAccuracy_A = []\n",
    "ValidationAccuracy_V = []\n",
    "ValidationAccuracy_A = []\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "\n",
    "class ValPadSequence:\n",
    "\tdef __call__(self, sorted_batch):\n",
    "\n",
    "\t\tsequences = [x[0] for x in sorted_batch]\n",
    "\t\taud_sequences = [x[1] for x in sorted_batch]\n",
    "\t\tspec_dim = []\n",
    "\t\tfor aud in aud_sequences:\n",
    "\t\t\tspec_dim.append(aud.shape[3])\n",
    "\n",
    "\t\tmax_spec_dim = max(spec_dim)\n",
    "\t\taudio_features = torch.zeros(len(spec_dim), 16, 1, 64, max_spec_dim)\n",
    "\t\tfor batch_idx, spectrogram in enumerate(aud_sequences):\n",
    "\t\t\tif spectrogram.shape[2] < max_spec_dim:\n",
    "\t\t\t\taudio_features[batch_idx, :, :, :, -spectrogram.shape[3]:] = spectrogram\n",
    "\t\t\telse:\n",
    "\t\t\t\taudio_features[batch_idx, :,:, :, :] = spectrogram\n",
    "\n",
    "\t\tframeids = [x[2] for x in sorted_batch]\n",
    "\t\tv_ids = [x[3] for x in sorted_batch]\n",
    "\t\tv_lengths = [x[4] for x in sorted_batch]\n",
    "\t\tlabelV = [x[5] for x in sorted_batch]\n",
    "\t\tlabelA = [x[6] for x in sorted_batch]\n",
    "\n",
    "\t\tvisual_sequences = torch.stack(sequences)\n",
    "\t\tlabelsV = torch.stack(labelV)\n",
    "\t\tlabelsA = torch.stack(labelA)\n",
    "\t\treturn visual_sequences, audio_features, frameids, v_ids, v_lengths, labelsV, labelsA\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_path = 'ABAW2020TNT/model2/TSAV_Sub4_544k.pth.tar' # path to the model\n",
    "model = TwoStreamAuralVisualModel(num_channels=4)\n",
    "saved_model = torch.load(model_path)\n",
    "model.load_state_dict(saved_model['state_dict'])\n",
    "\n",
    "new_first_layer = nn.Conv3d(in_channels=3,\n",
    "\t\t\t\t\tout_channels=model.video_model.r2plus1d.stem[0].out_channels,\n",
    "\t\t\t\t\tkernel_size=model.video_model.r2plus1d.stem[0].kernel_size,\n",
    "\t\t\t\t\tstride=model.video_model.r2plus1d.stem[0].stride,\n",
    "\t\t\t\t\tpadding=model.video_model.r2plus1d.stem[0].padding,\n",
    "\t\t\t\t\tbias=False)\n",
    "\n",
    "new_first_layer.weight.data = model.video_model.r2plus1d.stem[0].weight.data[:, 0:3]\n",
    "model.video_model.r2plus1d.stem[0] = new_first_layer\n",
    "model = nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "\n",
    "### Freezing the model\n",
    "for p in model.parameters():\n",
    "\tp.requires_grad = False\n",
    "for p in model.children():\n",
    "\tp.train(False)\n",
    " \n",
    "fusion_model = LSTM_CAM()\n",
    "# fusion_model = nn.DataParallel(fusion_model)\n",
    "# fusion_model.cuda()\n",
    "fusion_model = fusion_model.to(device=device)\n",
    "\n",
    "cam_model_path = f'SavedWeights/{test_weight_file}' # path to the model\n",
    "cam_saved_model = torch.load(cam_model_path)\n",
    "fusion_model.load_state_dict(cam_saved_model['net'])\n",
    "cammodel_accV = torch.load(cam_model_path)['best_Val_accV']\n",
    "cammodel_accA = torch.load(cam_model_path)['best_Val_accA']\n",
    "print(\"Saved cammodel_accV : \", cammodel_accV)\n",
    "print(\"Saved cammodel_accA : \", cammodel_accA)\n",
    "for param in fusion_model.parameters():  # children():\n",
    "    param.requires_grad = False\n",
    "\n",
    "config = \"config_file.json\"\n",
    "configuration = parse_configuration(config)\n",
    "\n",
    "dataset_rootpath = configuration['dataset_rootpath']\n",
    "dataset_wavspath = configuration['dataset_wavspath']\n",
    "dataset_labelpath = configuration['labelpath']\n",
    "\n",
    "def load_partition_set(partition_path, seed):\n",
    "\timport json\n",
    "\n",
    "\twith open(partition_path, 'r') as f:    \n",
    "\t\tseed_data = json.load(f)\n",
    "\n",
    "\tseed_data_train = seed_data[f'seed_{seed}']['Train_Set']\n",
    "\tseed_data_valid = seed_data[f'seed_{seed}']['Validation_Set']\n",
    "\tseed_data_test  = seed_data[f'seed_{seed}']['Test_Set']\n",
    " \n",
    "\tseed_data_train = [fn + \".csv\" for fn in seed_data_train]\n",
    "\tseed_data_valid = [fn + \".csv\" for fn in seed_data_valid]\n",
    "\tseed_data_test  = [fn + \".csv\" for fn in seed_data_test ]\n",
    "\n",
    "\treturn seed_data_train, seed_data_valid, seed_data_test\n",
    "\n",
    "partition_path = \"../data/Affwild2/seed_data.json\"\n",
    "train_set, valid_set, test_set = load_partition_set(partition_path, SEED)\n",
    "\n",
    "init_time = datetime.now()\n",
    "init_time = init_time.strftime('%m%d_%H%M')\n",
    "\n",
    "criterion = CCCLoss(digitize_num=1).cuda()\n",
    "\n",
    "testdataset = ImageList_val(root=configuration['dataset_rootpath'], fileList=test_set, labelPath=dataset_labelpath,\n",
    "\t\t\t\t\taudList=configuration['dataset_wavspath'], length=configuration['test_params']['seq_length'],\n",
    "\t\t\t\t\tflag='Test', stride=configuration['test_params']['stride'], dilation = configuration['test_params']['dilation'],\n",
    "\t\t\t\t\tsubseq_length = configuration['test_params']['subseq_length'])\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "\t\t\ttestdataset, collate_fn=ValPadSequence(),\n",
    "\t\t\t**configuration['test_params']['loader_params'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "import numpy as np\n",
    "import sys\n",
    "from EvaluationMetrics.cccmetric import ccc\n",
    "\n",
    "\n",
    "def Test(val_loader, model, criterion, cam):\n",
    "    # switch to evaluate mode\n",
    "    global Val_acc\n",
    "    global best_Val_acc\n",
    "    global best_Val_acc_epoch\n",
    "    #model.eval()\n",
    "    model.eval()\n",
    "    cam.eval()\n",
    "\n",
    "    vout = []\n",
    "    vtar = []\n",
    "    aout = []\n",
    "    atar = []\n",
    "\t#torch.cuda.synchronize()\n",
    "    #t7 = time.time()\n",
    "    pred_a = dict()\n",
    "    pred_v = dict()\n",
    "    label_a = dict()\n",
    "    label_v = dict()\n",
    "\t#files_dict = {}\n",
    "    count = 0\n",
    "    \n",
    "    vid_pred = {}\n",
    "    vid_label = {}\n",
    "    vid_ccc = {}\n",
    "    \n",
    "    for batch_idx, (visualdata, audiodata, frame_ids, videos, vid_lengths, labelsV, labelsA) in tqdm(enumerate(val_loader),\n",
    "                                                            total=len(val_loader), position=0, leave=True):\n",
    "        \n",
    "        audiodata = audiodata.cuda()#.unsqueeze(2)\n",
    "        visualdata = visualdata.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            b, seq_t, c, subseq_t, h, w = visualdata.size()\n",
    "            visual_feats = torch.empty((b, seq_t, 25088), dtype=visualdata.dtype, device = visualdata.device)\n",
    "            aud_feats = torch.empty((b, seq_t, 512), dtype=visualdata.dtype, device = visualdata.device)\n",
    "            for i in range(visualdata.shape[0]):\n",
    "                audio_feat, visualfeat, _ = model(audiodata[i,:,:,:], visualdata[i, :, :, :,:,:])\n",
    "                visual_feats[i,:,:] = visualfeat\n",
    "                aud_feats[i,:,:] = audio_feat\n",
    "\n",
    "            audiovisual_vouts,audiovisual_aouts = cam(aud_feats, visual_feats)\n",
    "\n",
    "            audiovisual_vouts = audiovisual_vouts.detach().cpu().numpy()\n",
    "            audiovisual_aouts = audiovisual_aouts.detach().cpu().numpy()\n",
    "\n",
    "            labelsV = labelsV.cpu().numpy()\n",
    "            labelsA = labelsA.cpu().numpy()\n",
    "\n",
    "            for voutputs, aoutputs, labelV, labelA, frameids, video, vid_length in zip(audiovisual_vouts, audiovisual_aouts, labelsV, labelsA, frame_ids, videos, vid_lengths):\n",
    "                for voutput, aoutput, labV, labA, frameid, vid, length in zip(voutputs, aoutputs, labelV, labelA, frameids, video, vid_length):\n",
    "                    if vid not in pred_a:\n",
    "                        if frameid>1:\n",
    "                            print(vid)\n",
    "                            print(length)\n",
    "                            print(\"something is wrong\")\n",
    "                            sys.exit()\n",
    "                        count = count + 1\n",
    "\n",
    "                        pred_a[vid] = [0]*length\n",
    "                        pred_v[vid] = [0]*length\n",
    "                        label_a[vid] = [0]*length\n",
    "                        label_v[vid] = [0]*length\n",
    "                        if labV == -5.0:\n",
    "                            continue\n",
    "                        pred_a[vid][frameid-1] = aoutput\n",
    "                        pred_v[vid][frameid-1] = voutput\n",
    "                        label_a[vid][frameid-1] = labA\n",
    "                        label_v[vid][frameid-1] = labV\n",
    "                    else:\n",
    "                        if frameid <= length:\n",
    "                            if labV == -5.0:\n",
    "                                continue\n",
    "                            pred_a[vid][frameid-1] = aoutput\n",
    "                            pred_v[vid][frameid-1] = voutput\n",
    "                            label_a[vid][frameid-1] = labA\n",
    "                            label_v[vid][frameid-1] = labV\n",
    "                            \n",
    "\n",
    "    for idx, key in enumerate(pred_a.keys()):\n",
    "        clipped_preds_v = np.clip(pred_v[key], -1.0, 1.0)\n",
    "        clipped_preds_a = np.clip(pred_a[key], -1.0, 1.0)\n",
    "\n",
    "        smoothened_preds_v = uniform_filter1d(clipped_preds_v, size=20, mode='constant')\n",
    "        smoothened_preds_a = uniform_filter1d(clipped_preds_a, size=50, mode='constant')\n",
    "        tars_v = label_v[key]\n",
    "        tars_a = label_a[key]\n",
    "        \n",
    "        key_vout = []\n",
    "        key_aout = []\n",
    "        key_vtar = []\n",
    "        key_atar = []\n",
    "\n",
    "        for i in range(len(smoothened_preds_a)):\n",
    "            vout.append(smoothened_preds_v[i])\n",
    "            aout.append(smoothened_preds_a[i])\n",
    "            vtar.append(tars_v[i])\n",
    "            atar.append(tars_a[i])\n",
    "            \n",
    "            key_vout.append(smoothened_preds_v[i])\n",
    "            key_aout.append(smoothened_preds_a[i])\n",
    "            key_vtar.append(tars_v[i])\n",
    "            key_atar.append(tars_a[i])\n",
    "                \n",
    "        vid_pred[key] = {\"vout\": type(key_vout), \"aout\": type(key_aout)}\n",
    "        vid_label[key] = {\"vtar\": type(key_vtar), \"atar\": type(key_atar)}\n",
    "        vid_ccc[key] = {\"vccc\": 0, \"accc\": 0}\n",
    "\n",
    "        vid_pred[key][\"vout\"] = key_vout\n",
    "        vid_pred[key][\"aout\"] = key_aout\n",
    "        vid_label[key][\"vtar\"] = key_vtar\n",
    "        vid_label[key][\"atar\"] = key_atar\n",
    "        vid_ccc[key]['vccc'] = ccc(np.array(key_vout), np.array(key_vtar))\n",
    "        vid_ccc[key]['accc'] = ccc(np.array(key_aout), np.array(key_atar))\n",
    "        \n",
    "\n",
    "    accV = ccc(np.array(vout), np.array(vtar))\n",
    "    accA = ccc(np.array(aout), np.array(atar))\n",
    "\n",
    "    print(accV)\n",
    "    print(accA)\n",
    "    return accV, accA, vid_pred, vid_label, vid_ccc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Test samples:25093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1569/1569 [4:45:53<00:00, 10.93s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49324594148986484\n",
      "0.5719829247946809\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Test samples:\" + str(len(testdataset)))\n",
    "Test_vacc, Test_aacc, vid_pred, vid_label, vid_ccc = Test(testloader, model, criterion, fusion_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'182': [0.16228741048320267, 0.6452682584307174, 0.40377783445696],\n",
       " '364': [0.3402849645167519, 0.4034233654558407, 0.3718541649862963],\n",
       " '69-25-854x480': [0.6096082908212413, 0.6481667360852625, 0.6288875134532519],\n",
       " '345': [0.32051638846547703, 0.2676686765752025, 0.29409253252033973],\n",
       " '228': [0.6148169537696062, 0.5507265969675325, 0.5827717753685693],\n",
       " '46-30-484x360_left': [0.32768446758482833,\n",
       "  0.46170762867938353,\n",
       "  0.3946960481321059],\n",
       " '216': [0.6368489922760667, 0.725613127720275, 0.6812310599981708],\n",
       " '140': [0.2981454618488699, 0.40942347062399415, 0.353784466236432],\n",
       " '153': [0.39736251426332436, 0.4044457826722771, 0.40090414846780076],\n",
       " '240': [0.4561297436073421, 0.3584377746911872, 0.4072837591492646],\n",
       " '5-60-1920x1080-4': [0.29332013021035713,\n",
       "  0.48297074288009845,\n",
       "  0.3881454365452278],\n",
       " '412': [0.1268741081240879, -0.005474905737903692, 0.060699601193092104],\n",
       " '308': [0.033429097225202944, 0.1804273618681957, 0.10692822954669931],\n",
       " '137': [-0.17406381745323596, 0.3696191680272098, 0.09777767528698691],\n",
       " '279': [0.46213257732733243, 0.11010729987192272, 0.2861199385996276],\n",
       " '94-30-1920x1080': [0.1180518278070721,\n",
       "  -0.1447382626594857,\n",
       "  -0.013343217426206797],\n",
       " '210': [0.29015707562240106, 0.6627090921613726, 0.4764330838918869],\n",
       " '47-30-654x480': [0.36456054081095957,\n",
       "  0.46833805243438636,\n",
       "  0.41644929662267294],\n",
       " '319': [0.6715822777591565, 0.5904523334386077, 0.6310173055988821],\n",
       " '235': [0.22076334880860082, 0.491760611525103, 0.3562619801668519],\n",
       " '110-30-270x480': [-0.0018729878227612066,\n",
       "  0.06581100778246989,\n",
       "  0.031969009979854336],\n",
       " '186': [0.2259092024348706, 0.7723764253013, 0.4991428138680853],\n",
       " '90-30-1080x1920': [0.44090930201711553,\n",
       "  0.4730245589622082,\n",
       "  0.45696693048966186],\n",
       " '317': [0.7250099739845178, 0.7950691751359259, 0.7600395745602219],\n",
       " '385': [0.4375992668525547, 0.384480203094254, 0.41103973497340435],\n",
       " '41-24-1280x720': [0.12251704579884902,\n",
       "  0.4548747105341816,\n",
       "  0.2886958781665153],\n",
       " '384': [0.02612130657448036, 0.6466472303688181, 0.3363842684716492],\n",
       " '120': [0.46103726152626084, 0.46224820319622545, 0.46164273236124315],\n",
       " '335': [0.03930035112436127, 0.5664885384082243, 0.3028944447662928],\n",
       " '395': [0.33615714978305455, 0.36462469650066637, 0.3503909231418605],\n",
       " '23-24-1920x1080': [0.21645512026833208,\n",
       "  0.41838273118519476,\n",
       "  0.31741892572676345],\n",
       " '326': [0.2874483823686992, 0.3910611848702052, 0.33925478361945216],\n",
       " '227': [0.19047775541046105, 0.3704277788343212, 0.28045276712239114],\n",
       " '46-30-484x360_right': [0.5011540273170473,\n",
       "  0.4452062946781486,\n",
       "  0.47318016099759797],\n",
       " '131': [0.2932923585081121, 0.3632957141610499, 0.328294036334581],\n",
       " '185': [0.6503431281548365, 0.6546749297177415, 0.652509028936289],\n",
       " '106-30-720x1280': [0.32713021838914713,\n",
       "  0.42993698154875154,\n",
       "  0.3785335999689493],\n",
       " '163': [0.5954871497589884, 0.6442914777871345, 0.6198893137730614],\n",
       " '114': [0.385831201788111, 0.4172747246943339, 0.40155296324122247],\n",
       " '198': [0.03336286729483193, 0.3854552147764991, 0.2094090410356655],\n",
       " '28-30-1280x720-1': [-0.08684076427567658,\n",
       "  0.7728603328407804,\n",
       "  0.3430097842825519],\n",
       " '213': [0.037988597153115776, 0.19266073527824437, 0.11532466621568008],\n",
       " '28-30-1280x720-3': [0.021798355187140447,\n",
       "  0.6491124920153168,\n",
       "  0.33545542360122865],\n",
       " '320': [0.5315243575766818, 0.4954132043161683, 0.5134687809464251],\n",
       " '151': [0.10697894421874013, 0.4007231772599312, 0.25385106073933567],\n",
       " '298': [0.598566541461442, 0.5617595286703486, 0.5801630350658953],\n",
       " '447': [-0.2161079148363803, 0.5194030417611606, 0.15164756346239014],\n",
       " '135-24-1920x1080_right': [0.4948766113989058,\n",
       "  0.26636399431316304,\n",
       "  0.38062030285603443],\n",
       " '100-29-1080x1920': [0.7253561423922968,\n",
       "  0.7595205745456478,\n",
       "  0.7424383584689723],\n",
       " '427': [0.7604566348112716, 0.7524977321058283, 0.75647718345855],\n",
       " '107': [0.07162477032673072, 0.1582554818504607, 0.11494012608859572],\n",
       " '39-25-424x240': [0.3176194418785401, 0.7951848087741867, 0.5564021253263634],\n",
       " '126': [0.4545875530796716, 0.45981255872400845, 0.45720005590184],\n",
       " '346': [0.421680969767536, 0.2579880748914365, 0.33983452232948624],\n",
       " '368': [0.09892081644953309, 0.49186023067834406, 0.2953905235639386],\n",
       " '435': [0.38263238057982346, 0.09536931363993313, 0.2390008471098783],\n",
       " '149': [0.030601791234137653, 0.2899691962180063, 0.16028549372607198],\n",
       " '129': [0.13464812143880348, 0.19292941755416165, 0.16378876949648258],\n",
       " '15-24-1920x1080': [0.19025957355176978,\n",
       "  0.15369645203055507,\n",
       "  0.17197801279116243],\n",
       " '24-30-1920x1080-1': [0.5704448728804565,\n",
       "  0.5072548504980873,\n",
       "  0.5388498616892718],\n",
       " '92-24-1920x1080': [0.6648205399489634,\n",
       "  0.5563897122803279,\n",
       "  0.6106051261146457],\n",
       " '136-30-1920x1080': [0.2650145083157204,\n",
       "  0.5729651603964846,\n",
       "  0.4189898343561025],\n",
       " '101-30-1080x1920': [0.5069534879716949,\n",
       "  0.374716847591531,\n",
       "  0.44083516778161297],\n",
       " '363': [0.5455889847866467, 0.5896401703053188, 0.5676145775459828],\n",
       " '440': [0.5844187098708209, 0.3505133659414131, 0.46746603790611696],\n",
       " '327': [0.49291573082701395, 0.5561553204654014, 0.5245355256462076],\n",
       " 'video59_right': [0.5983280402029556,\n",
       "  0.2573695486232003,\n",
       "  0.42784879441307794],\n",
       " 'video62': [0.1305337784090624, 0.2626517556221363, 0.19659276701559936],\n",
       " 'video85': [0.05846320785159516, 0.29409470741258564, 0.1762789576320904],\n",
       " '107-30-640x480': [-0.006692005038718922,\n",
       "  0.024928707069845416,\n",
       "  0.009118351015563247],\n",
       " 'video66': [0.09934178428908425, 0.29704213958693604, 0.19819196193801014],\n",
       " '1-30-1280x720': [0.20491731382988432,\n",
       "  0.15739805848458616,\n",
       "  0.18115768615723524],\n",
       " 'video55_left': [0.06291723526013024,\n",
       "  0.3063561742026533,\n",
       "  0.18463670473139177],\n",
       " 'video59': [0.38657627607107403, 0.618830411651157, 0.5027033438611155],\n",
       " 'video93': [0.16321503025810108, -0.039843139341088483, 0.061685945458506294],\n",
       " '113-60-1280x720': [-0.25430542792917243,\n",
       "  -0.16396478960689567,\n",
       "  -0.20913510876803404],\n",
       " '21-24-1920x1080': [0.8617468437629875,\n",
       "  0.2090815667692501,\n",
       "  0.5354142052661188],\n",
       " 'video70': [0.28994507805447567, 0.5742955731797603, 0.432120325617118],\n",
       " 'video94': [0.20987800181911115, 0.15495970638581952, 0.18241885410246533],\n",
       " 'video64': [0.2567668589096735, 0.2410950543107155, 0.2489309566101945],\n",
       " 'video74_right': [0.44416555319753254, 0.627574245808647, 0.5358698995030897],\n",
       " 'video61': [0.6563924607688267, 0.5318145826747743, 0.5941035217218005],\n",
       " 'video58': [nan, nan, nan]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ccc_result = {} # {\"vid\" : [valence, arousal, mean]}\n",
    "for k in vid_ccc.keys():\n",
    "    new_ccc_result[k] = [vid_ccc[k]['vccc'], vid_ccc[k]['accc'], np.mean([vid_ccc[k]['vccc'], vid_ccc[k]['accc']])]\n",
    "    \n",
    "new_ccc_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('113-60-1280x720',\n",
       "  [-0.25430542792917243, -0.16396478960689567, -0.20913510876803404]),\n",
       " ('94-30-1920x1080',\n",
       "  [0.1180518278070721, -0.1447382626594857, -0.013343217426206797]),\n",
       " ('107-30-640x480',\n",
       "  [-0.006692005038718922, 0.024928707069845416, 0.009118351015563247]),\n",
       " ('110-30-270x480',\n",
       "  [-0.0018729878227612066, 0.06581100778246989, 0.031969009979854336]),\n",
       " ('412', [0.1268741081240879, -0.005474905737903692, 0.060699601193092104]),\n",
       " ('video93',\n",
       "  [0.16321503025810108, -0.039843139341088483, 0.061685945458506294]),\n",
       " ('137', [-0.17406381745323596, 0.3696191680272098, 0.09777767528698691]),\n",
       " ('308', [0.033429097225202944, 0.1804273618681957, 0.10692822954669931]),\n",
       " ('107', [0.07162477032673072, 0.1582554818504607, 0.11494012608859572]),\n",
       " ('213', [0.037988597153115776, 0.19266073527824437, 0.11532466621568008]),\n",
       " ('447', [-0.2161079148363803, 0.5194030417611606, 0.15164756346239014]),\n",
       " ('149', [0.030601791234137653, 0.2899691962180063, 0.16028549372607198]),\n",
       " ('129', [0.13464812143880348, 0.19292941755416165, 0.16378876949648258]),\n",
       " ('15-24-1920x1080',\n",
       "  [0.19025957355176978, 0.15369645203055507, 0.17197801279116243]),\n",
       " ('video85', [0.05846320785159516, 0.29409470741258564, 0.1762789576320904]),\n",
       " ('1-30-1280x720',\n",
       "  [0.20491731382988432, 0.15739805848458616, 0.18115768615723524]),\n",
       " ('video94', [0.20987800181911115, 0.15495970638581952, 0.18241885410246533]),\n",
       " ('video55_left',\n",
       "  [0.06291723526013024, 0.3063561742026533, 0.18463670473139177]),\n",
       " ('video62', [0.1305337784090624, 0.2626517556221363, 0.19659276701559936]),\n",
       " ('video66', [0.09934178428908425, 0.29704213958693604, 0.19819196193801014]),\n",
       " ('198', [0.03336286729483193, 0.3854552147764991, 0.2094090410356655]),\n",
       " ('435', [0.38263238057982346, 0.09536931363993313, 0.2390008471098783]),\n",
       " ('video64', [0.2567668589096735, 0.2410950543107155, 0.2489309566101945]),\n",
       " ('151', [0.10697894421874013, 0.4007231772599312, 0.25385106073933567]),\n",
       " ('227', [0.19047775541046105, 0.3704277788343212, 0.28045276712239114]),\n",
       " ('279', [0.46213257732733243, 0.11010729987192272, 0.2861199385996276]),\n",
       " ('41-24-1280x720',\n",
       "  [0.12251704579884902, 0.4548747105341816, 0.2886958781665153]),\n",
       " ('345', [0.32051638846547703, 0.2676686765752025, 0.29409253252033973]),\n",
       " ('368', [0.09892081644953309, 0.49186023067834406, 0.2953905235639386]),\n",
       " ('335', [0.03930035112436127, 0.5664885384082243, 0.3028944447662928]),\n",
       " ('23-24-1920x1080',\n",
       "  [0.21645512026833208, 0.41838273118519476, 0.31741892572676345]),\n",
       " ('131', [0.2932923585081121, 0.3632957141610499, 0.328294036334581]),\n",
       " ('28-30-1280x720-3',\n",
       "  [0.021798355187140447, 0.6491124920153168, 0.33545542360122865]),\n",
       " ('384', [0.02612130657448036, 0.6466472303688181, 0.3363842684716492]),\n",
       " ('326', [0.2874483823686992, 0.3910611848702052, 0.33925478361945216]),\n",
       " ('346', [0.421680969767536, 0.2579880748914365, 0.33983452232948624]),\n",
       " ('28-30-1280x720-1',\n",
       "  [-0.08684076427567658, 0.7728603328407804, 0.3430097842825519]),\n",
       " ('395', [0.33615714978305455, 0.36462469650066637, 0.3503909231418605]),\n",
       " ('140', [0.2981454618488699, 0.40942347062399415, 0.353784466236432]),\n",
       " ('235', [0.22076334880860082, 0.491760611525103, 0.3562619801668519]),\n",
       " ('364', [0.3402849645167519, 0.4034233654558407, 0.3718541649862963]),\n",
       " ('106-30-720x1280',\n",
       "  [0.32713021838914713, 0.42993698154875154, 0.3785335999689493]),\n",
       " ('135-24-1920x1080_right',\n",
       "  [0.4948766113989058, 0.26636399431316304, 0.38062030285603443]),\n",
       " ('5-60-1920x1080-4',\n",
       "  [0.29332013021035713, 0.48297074288009845, 0.3881454365452278]),\n",
       " ('46-30-484x360_left',\n",
       "  [0.32768446758482833, 0.46170762867938353, 0.3946960481321059]),\n",
       " ('153', [0.39736251426332436, 0.4044457826722771, 0.40090414846780076]),\n",
       " ('114', [0.385831201788111, 0.4172747246943339, 0.40155296324122247]),\n",
       " ('182', [0.16228741048320267, 0.6452682584307174, 0.40377783445696]),\n",
       " ('240', [0.4561297436073421, 0.3584377746911872, 0.4072837591492646]),\n",
       " ('385', [0.4375992668525547, 0.384480203094254, 0.41103973497340435]),\n",
       " ('47-30-654x480',\n",
       "  [0.36456054081095957, 0.46833805243438636, 0.41644929662267294]),\n",
       " ('136-30-1920x1080',\n",
       "  [0.2650145083157204, 0.5729651603964846, 0.4189898343561025]),\n",
       " ('video59_right',\n",
       "  [0.5983280402029556, 0.2573695486232003, 0.42784879441307794]),\n",
       " ('video70', [0.28994507805447567, 0.5742955731797603, 0.432120325617118]),\n",
       " ('101-30-1080x1920',\n",
       "  [0.5069534879716949, 0.374716847591531, 0.44083516778161297]),\n",
       " ('90-30-1080x1920',\n",
       "  [0.44090930201711553, 0.4730245589622082, 0.45696693048966186]),\n",
       " ('126', [0.4545875530796716, 0.45981255872400845, 0.45720005590184]),\n",
       " ('120', [0.46103726152626084, 0.46224820319622545, 0.46164273236124315]),\n",
       " ('440', [0.5844187098708209, 0.3505133659414131, 0.46746603790611696]),\n",
       " ('46-30-484x360_right',\n",
       "  [0.5011540273170473, 0.4452062946781486, 0.47318016099759797]),\n",
       " ('210', [0.29015707562240106, 0.6627090921613726, 0.4764330838918869]),\n",
       " ('186', [0.2259092024348706, 0.7723764253013, 0.4991428138680853]),\n",
       " ('video59', [0.38657627607107403, 0.618830411651157, 0.5027033438611155]),\n",
       " ('320', [0.5315243575766818, 0.4954132043161683, 0.5134687809464251]),\n",
       " ('327', [0.49291573082701395, 0.5561553204654014, 0.5245355256462076]),\n",
       " ('21-24-1920x1080',\n",
       "  [0.8617468437629875, 0.2090815667692501, 0.5354142052661188]),\n",
       " ('video74_right',\n",
       "  [0.44416555319753254, 0.627574245808647, 0.5358698995030897]),\n",
       " ('24-30-1920x1080-1',\n",
       "  [0.5704448728804565, 0.5072548504980873, 0.5388498616892718]),\n",
       " ('39-25-424x240',\n",
       "  [0.3176194418785401, 0.7951848087741867, 0.5564021253263634]),\n",
       " ('363', [0.5455889847866467, 0.5896401703053188, 0.5676145775459828]),\n",
       " ('298', [0.598566541461442, 0.5617595286703486, 0.5801630350658953]),\n",
       " ('228', [0.6148169537696062, 0.5507265969675325, 0.5827717753685693]),\n",
       " ('video61', [0.6563924607688267, 0.5318145826747743, 0.5941035217218005]),\n",
       " ('92-24-1920x1080',\n",
       "  [0.6648205399489634, 0.5563897122803279, 0.6106051261146457]),\n",
       " ('163', [0.5954871497589884, 0.6442914777871345, 0.6198893137730614]),\n",
       " ('69-25-854x480',\n",
       "  [0.6096082908212413, 0.6481667360852625, 0.6288875134532519]),\n",
       " ('319', [0.6715822777591565, 0.5904523334386077, 0.6310173055988821]),\n",
       " ('185', [0.6503431281548365, 0.6546749297177415, 0.652509028936289]),\n",
       " ('216', [0.6368489922760667, 0.725613127720275, 0.6812310599981708]),\n",
       " ('100-29-1080x1920',\n",
       "  [0.7253561423922968, 0.7595205745456478, 0.7424383584689723]),\n",
       " ('427', [0.7604566348112716, 0.7524977321058283, 0.75647718345855]),\n",
       " ('317', [0.7250099739845178, 0.7950691751359259, 0.7600395745602219]),\n",
       " ('video58', [nan, nan, nan])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_vid = sorted(new_ccc_result.items(), key=lambda x: x[1][2])\n",
    "sort_vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import openpyxl\n",
    "\n",
    "xl_dir_path = \"xl_dir\"\n",
    "if not os.path.exists(xl_dir_path):\n",
    "    os.makedirs(xl_dir_path)\n",
    "\n",
    "columns = [\"file_name\", \"infer_val\", \"infer_aro\", \"infer_mean\", \"anno_val\", \"anno_aro\", \"anno_mean\"]\n",
    "file_values_dict = {c:[] for c in columns}\n",
    "\n",
    "columns = list(file_values_dict.keys())\n",
    "orig_label = vid_label\n",
    "\n",
    "for vid,score_list in sort_vid:\n",
    "    file_values_dict['file_name'].append(vid)\n",
    "    \n",
    "    file_values_dict['infer_val'].append(np.round(score_list[0], 3))\n",
    "    file_values_dict['infer_aro'].append(np.round(score_list[1], 3))\n",
    "    file_values_dict['infer_mean'].append(np.round(score_list[2], 3))\n",
    "    \n",
    "    \n",
    "    orig_label_arousal = np.mean(orig_label[vid]['atar'])\n",
    "    orig_label_valence = np.mean(orig_label[vid]['vtar'])\n",
    "    \n",
    "    file_values_dict['anno_val'].append(np.round(orig_label_arousal, 3))\n",
    "    file_values_dict['anno_aro'].append(np.round(orig_label_valence, 3))\n",
    "    \n",
    "    orig_label_mean = np.mean([orig_label_arousal, orig_label_valence])\n",
    "    file_values_dict['anno_mean'].append(np.round(orig_label_mean, 3))    \n",
    "    \n",
    "    \n",
    "xl_file_name = f\"paper3_score_csv_file_{SEED}.xlsx\"\n",
    "xl_file = os.path.join(xl_dir_path, xl_file_name)\n",
    "\n",
    "if not os.path.exists(xl_file):\n",
    "    wb=openpyxl.Workbook()\n",
    "    wb.save(xl_file)\n",
    "    \n",
    "full_record_df = pd.DataFrame(file_values_dict, columns=columns) # todo    \n",
    "    \n",
    "# full_records 시트를 작성하여 파일을 생성\n",
    "with pd.ExcelWriter(xl_file, mode='w', engine='openpyxl') as writer:\n",
    "    full_record_df.to_excel(writer, sheet_name=\"full_records\", index=False, encoding='utf-8')\n",
    "    \n",
    "with pd.ExcelWriter(xl_file, mode='a', engine='openpyxl') as writer:\n",
    "    for vid, scores in sort_vid:\n",
    "        va_df_dict = {\n",
    "            \"pred_val\" : [],\n",
    "            \"pred_aro\" : [],\n",
    "            \"label_val\" : [],\n",
    "            \"label_aro\" : []\n",
    "        }\n",
    "        va_df_dict[\"pred_val\"].extend(vid_pred[vid]['vout'])\n",
    "        va_df_dict[\"pred_aro\"].extend(vid_pred[vid]['aout'])\n",
    "        va_df_dict[\"label_val\"].extend(vid_label[vid]['vtar'])\n",
    "        va_df_dict[\"label_aro\"].extend(vid_label[vid]['atar'])\n",
    "        \n",
    "        va_df = pd.DataFrame(va_df_dict, columns=va_df_dict.keys())\n",
    "        va_df.to_excel(writer, sheet_name=vid, index=False)\n",
    "        \n",
    "    writer.save()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = \"save/results/lstm_overall_results_ccc.csv\"\n",
    "record_v, record_a, record_m = f\"{Test_vacc:.3f}\", f\"{Test_aacc:.3f}\", f\"{np.mean([Test_vacc, Test_aacc]):.3f}\"\n",
    "\n",
    "result_col = [\"seed\", \"Valence_ccc\", \"Arousal_ccc\", \"Mean_CCC\"]\n",
    "record = [SEED, record_v, record_a, record_m]\n",
    "\n",
    "df = pd.DataFrame([record], columns=result_col)\n",
    "if not os.path.exists(result_path):\n",
    "    df.to_csv(result_path, index=False)\n",
    "else:\n",
    "    df.to_csv(result_path, mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set에 대한 최종 표준편차까지 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>Valence_ccc</th>\n",
       "      <th>Arousal_ccc</th>\n",
       "      <th>Mean_CCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seed  Valence_ccc  Arousal_ccc  Mean_CCC\n",
       "0   0.0        0.606        0.602     0.604\n",
       "1   1.0        0.647        0.631     0.639\n",
       "2   2.0        0.648        0.592     0.620\n",
       "3   4.0        0.493        0.572     0.533"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>Valence_ccc</th>\n",
       "      <th>Arousal_ccc</th>\n",
       "      <th>Mean_CCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  seed Valence_ccc Arousal_ccc Mean_CCC\n",
       "0    0       0.606       0.602    0.604\n",
       "1    1       0.647       0.631    0.639\n",
       "2    2       0.648       0.592    0.620\n",
       "3    4       0.493       0.572    0.533"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_path = \"save/results/lstm_overall_results_ccc.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "data = data[~(data['seed'] == \"result\")]\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "for k in data:\n",
    "    data[k] = data[k].astype(np.float32)\n",
    "\n",
    "display(data)\n",
    "\n",
    "res = {}\n",
    "res['seed'] = \"result\"\n",
    "res['Valence_ccc']  = f\"{np.mean(data['Valence_ccc']):.3f} ± {np.std(data['Valence_ccc']):.3f}\"\n",
    "res['Arousal_ccc']  = f\"{np.mean(data['Arousal_ccc']):.3f} ± {np.std(data['Arousal_ccc']):.3f}\"\n",
    "res['Mean_CCC']     = f\"{np.mean(data['Mean_CCC']):.3f} ± {np.std(data['Mean_CCC']):.3f}\"\n",
    "\n",
    "\n",
    "data['seed'] = data['seed'].apply(lambda x : f\"{x:.0f}\")\n",
    "data['Valence_ccc'] = data['Valence_ccc'].apply(lambda x : f\"{x:.3f}\")\n",
    "data['Arousal_ccc'] = data['Arousal_ccc'].apply(lambda x : f\"{x:.3f}\")\n",
    "data['Mean_CCC'] = data['Mean_CCC'].apply(lambda x : f\"{x:.3f}\")\n",
    "\n",
    "display(data)\n",
    "\n",
    "data = data.append(res, ignore_index=True)\n",
    "data.to_csv(data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Load the Excel file\n",
    "# file_path22 = 'xl_dir/paper3_score_csv_file_0_nan387.xlsx'\n",
    "\n",
    "# # Load the 'full_records' sheet\n",
    "# old_data = pd.read_excel(file_path22, sheet_name='full_records')\n",
    "\n",
    "# # Display the first few rows of the dataframe to understand its structure\n",
    "# old_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# data = old_data[~((old_data['file_name'] == '387') & (old_data['file_name'] == '389'))]\n",
    "# np.mean(data.loc[:, ['infer_val', 'infer_aro', 'infer_mean']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Multimodal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
