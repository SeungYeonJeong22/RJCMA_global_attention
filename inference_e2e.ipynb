{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from base.dataset import ABAW2_VA_Arranger, ABAW2_VA_Dataset\n",
    "from model.model import my_2d1ddy\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from base.logger import ContinuousOutputHandlerNPYTrial, ContinuousMetricsCalculatorTrial\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import openpyxl\n",
    "\n",
    "batch_size = 16\n",
    "window_length = 300\n",
    "hop_length = 200\n",
    "debug = 0\n",
    "fold = 0\n",
    "time_delay = 0\n",
    "train_emotion = 'both'\n",
    "modality = ['frame', 'mfcc', 'vggish']\n",
    "head = \"multi-headed\"\n",
    "\n",
    "backbone_state_dict = \"res50_ir_0.887\"\n",
    "backbone_mode = \"ir\"\n",
    "cnn1d_embedding_dim = 512\n",
    "cnn1d_channels = [128,128,128,128]\n",
    "output_dim = 2\n",
    "cnn1d_kernel_size = 5\n",
    "cnn1d_attention = 0\n",
    "cnn1d_dropout = 0.1\n",
    "model_load_path = \"load\"\n",
    "\n",
    "root_path = \"save\"\n",
    "model_state_dict_path_list = []\n",
    "\n",
    "class CCCLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, gold, pred, weights=None):\n",
    "        # pred = torch.tanh(pred)\n",
    "        gold_mean = torch.mean(gold, 1, keepdim=True, out=None)\n",
    "        pred_mean = torch.mean(pred, 1, keepdim=True, out=None)\n",
    "        covariance = (gold - gold_mean) * (pred - pred_mean)\n",
    "        gold_var = torch.var(gold, 1, keepdim=True, unbiased=True, out=None)\n",
    "        pred_var = torch.var(pred, 1, keepdim=True, unbiased=True, out=None)\n",
    "        ccc = 2. * covariance / (\n",
    "                (gold_var + pred_var + torch.mul(gold_mean - pred_mean, gold_mean - pred_mean)) + 1e-08)\n",
    "        ccc_loss = 1. - ccc\n",
    "\n",
    "        if weights is not None:\n",
    "            ccc_loss *= weights\n",
    "\n",
    "        return torch.mean(ccc_loss)\n",
    "    \n",
    "def get_train_emotion(emotion_tag, head):\n",
    "\n",
    "    emotion = [\"Valence\", \"Arousal\"]\n",
    "\n",
    "    if emotion_tag == \"arousal\":\n",
    "        if head == \"sh\":\n",
    "            emotion = [\"Arousal\"]\n",
    "    elif emotion_tag == \"valence\":\n",
    "        if head == \"sh\":\n",
    "            emotion = [\"Valence\"]\n",
    "\n",
    "    return emotion\n",
    "\n",
    "from tqdm import tqdm\n",
    "from base.logger import ContinuousOutputHandlerNPYTrial, ContinuousMetricsCalculatorTrial\n",
    "\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "emotional_dimension = get_train_emotion(train_emotion, head)\n",
    "metrics = ['ccc']\n",
    "    \n",
    "\n",
    "criterion = CCCLoss()\n",
    "\n",
    "trials_pred = {}\n",
    "\n",
    "loss_dict = {}\n",
    "\n",
    "def loop(data_loader, train_mode=False):\n",
    "    output_handler = ContinuousOutputHandlerNPYTrial(emotional_dimension)\n",
    "    continuous_label_handler = ContinuousOutputHandlerNPYTrial(emotional_dimension)    \n",
    "    \n",
    "    metric_handler = ContinuousMetricsCalculatorTrial(metrics, emotional_dimension,\n",
    "                                                        output_handler, continuous_label_handler)\n",
    "    \n",
    "    total_batch_counter = 0\n",
    "    for batch_index, (X, Y, trials, lengths, indices) in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "        total_batch_counter += len(trials)    \n",
    "    \n",
    "        if 'frame' in X:\n",
    "            inputs = X['frame'].to(device)\n",
    "\n",
    "        if 'mfcc' in X:\n",
    "            inputs3 = X['mfcc'].to(device)\n",
    "\n",
    "        if 'vggish' in X:\n",
    "            inputs4 = X['vggish'].to(device)\n",
    "\n",
    "        labels = Y.float().to(device)\n",
    "        loss_weights = torch.ones_like(labels).to(device)\n",
    "        \n",
    "        outputs = model(inputs, inputs4, inputs3)\n",
    "        \n",
    "        output_handler.update_output_for_seen_trials(outputs.detach().cpu().numpy(), trials, indices, lengths)\n",
    "        continuous_label_handler.update_output_for_seen_trials(labels.detach().cpu().numpy(), trials, indices, lengths)\n",
    "        \n",
    "        \n",
    "        loss = criterion(outputs, labels, loss_weights)\n",
    "        \n",
    "        for i in range(len(trials)):\n",
    "            try:\n",
    "                trials_pred[trials[i]] = torch.cat([trials_pred[trials[i]], outputs[i]], dim=0)\n",
    "                loss_dict[trials[i]].append(loss)\n",
    "            except:\n",
    "                trials_pred[trials[i]] = outputs[i]\n",
    "                loss_dict[trials[i]] = [loss]\n",
    "            \n",
    "    output_handler.average_trial_wise_records()\n",
    "    continuous_label_handler.average_trial_wise_records()\n",
    "\n",
    "    output_handler.concat_records()\n",
    "    continuous_label_handler.concat_records()\n",
    "    \n",
    "    metric_handler.calculate_metrics()\n",
    "    \n",
    "    return outputs, trials_pred, loss_dict, output_handler, continuous_label_handler, metric_handler\n",
    "    \n",
    "\n",
    "for i in os.listdir(root_path):\n",
    "    if i.__contains__(\"pre\") or i .__contains__(\"results\"): continue\n",
    "    model_dir_path = os.path.join(root_path, i, \"0\")\n",
    "    model_path = os.path.join(model_dir_path, \"model_state_dict.pth\")\n",
    "    model_state_dict_path_list.append(model_path)\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "xl_dir_path = \"xl_dir\"\n",
    "if not os.path.exists(xl_dir_path):\n",
    "    os.makedirs(xl_dir_path)\n",
    "\n",
    "init_time = datetime.now()\n",
    "init_time = init_time.strftime('%m%d_%H%M')\n",
    "csv_name = f\"{xl_dir_path}/{init_time}_test_score.csv\"\n",
    "\n",
    "columns = [\"Seed\", \"CCC_Valence\", \"CCC_Arousal\", \"CCC_Mean\"]\n",
    "init_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "init_df.to_csv(csv_name, index=False)\n",
    "file_values_dict = {c:[] for c in columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104/104 [21:14<00:00, 12.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before sort_vid len :  84\n",
      "after sort_vid len :  83\n",
      "['0.405±0.288']\n",
      "['0.454±0.233']\n",
      "['0.43±0.218']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [25:46<00:00, 12.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before sort_vid len :  84\n",
      "after sort_vid len :  83\n",
      "['0.405±0.288', '0.402±0.228']\n",
      "['0.454±0.233', '0.442±0.234']\n",
      "['0.43±0.218', '0.422±0.198']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [26:25<00:00, 11.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before sort_vid len :  84\n",
      "after sort_vid len :  83\n",
      "['0.405±0.288', '0.402±0.228', '0.389±0.242']\n",
      "['0.454±0.233', '0.442±0.234', '0.441±0.219']\n",
      "['0.43±0.218', '0.422±0.198', '0.415±0.196']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [18:58<00:00, 11.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before sort_vid len :  84\n",
      "after sort_vid len :  83\n",
      "['0.405±0.288', '0.402±0.228', '0.389±0.242', '0.343±0.255']\n",
      "['0.454±0.233', '0.442±0.234', '0.441±0.219', '0.417±0.269']\n",
      "['0.43±0.218', '0.422±0.198', '0.415±0.196', '0.38±0.235']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [24:07<00:00, 12.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before sort_vid len :  84\n",
      "after sort_vid len :  83\n",
      "['0.405±0.288', '0.402±0.228', '0.389±0.242', '0.343±0.255', '0.392±0.287']\n",
      "['0.454±0.233', '0.442±0.234', '0.441±0.219', '0.417±0.269', '0.453±0.248']\n",
      "['0.43±0.218', '0.422±0.198', '0.415±0.196', '0.38±0.235', '0.423±0.225']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 123/123 [28:22<00:00, 13.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before sort_vid len :  84\n",
      "after sort_vid len :  83\n",
      "['0.405±0.288', '0.402±0.228', '0.389±0.242', '0.343±0.255', '0.392±0.287', '0.38±0.256']\n",
      "['0.454±0.233', '0.442±0.234', '0.441±0.219', '0.417±0.269', '0.453±0.248', '0.432±0.238']\n",
      "['0.43±0.218', '0.422±0.198', '0.415±0.196', '0.38±0.235', '0.423±0.225', '0.406±0.217']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [27:23<00:00, 12.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before sort_vid len :  84\n",
      "after sort_vid len :  83\n",
      "['0.405±0.288', '0.402±0.228', '0.389±0.242', '0.343±0.255', '0.392±0.287', '0.38±0.256', '0.383±0.264']\n",
      "['0.454±0.233', '0.442±0.234', '0.441±0.219', '0.417±0.269', '0.453±0.248', '0.432±0.238', '0.402±0.231']\n",
      "['0.43±0.218', '0.422±0.198', '0.415±0.196', '0.38±0.235', '0.423±0.225', '0.406±0.217', '0.392±0.221']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126/126 [27:25<00:00, 13.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before sort_vid len :  84\n",
      "after sort_vid len :  83\n",
      "['0.405±0.288', '0.402±0.228', '0.389±0.242', '0.343±0.255', '0.392±0.287', '0.38±0.256', '0.383±0.264', '0.347±0.276']\n",
      "['0.454±0.233', '0.442±0.234', '0.441±0.219', '0.417±0.269', '0.453±0.248', '0.432±0.238', '0.402±0.231', '0.414±0.229']\n",
      "['0.43±0.218', '0.422±0.198', '0.415±0.196', '0.38±0.235', '0.423±0.225', '0.406±0.217', '0.392±0.221', '0.381±0.212']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [22:54<00:00, 11.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before sort_vid len :  84\n",
      "after sort_vid len :  83\n",
      "['0.405±0.288', '0.402±0.228', '0.389±0.242', '0.343±0.255', '0.392±0.287', '0.38±0.256', '0.383±0.264', '0.347±0.276', '0.366±0.24']\n",
      "['0.454±0.233', '0.442±0.234', '0.441±0.219', '0.417±0.269', '0.453±0.248', '0.432±0.238', '0.402±0.231', '0.414±0.229', '0.412±0.24']\n",
      "['0.43±0.218', '0.422±0.198', '0.415±0.196', '0.38±0.235', '0.423±0.225', '0.406±0.217', '0.392±0.221', '0.381±0.212', '0.389±0.206']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [26:17<00:00, 13.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before sort_vid len :  84\n",
      "after sort_vid len :  83\n",
      "['0.405±0.288', '0.402±0.228', '0.389±0.242', '0.343±0.255', '0.392±0.287', '0.38±0.256', '0.383±0.264', '0.347±0.276', '0.366±0.24', '0.417±0.282']\n",
      "['0.454±0.233', '0.442±0.234', '0.441±0.219', '0.417±0.269', '0.453±0.248', '0.432±0.238', '0.402±0.231', '0.414±0.229', '0.412±0.24', '0.435±0.245']\n",
      "['0.43±0.218', '0.422±0.198', '0.415±0.196', '0.38±0.235', '0.423±0.225', '0.406±0.217', '0.392±0.221', '0.381±0.212', '0.389±0.206', '0.426±0.219']\n"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "for seed in range(10):\n",
    "    model_state_dict_path = model_state_dict_path_list[seed]\n",
    "    model_state_dict = torch.load(model_state_dict_path)\n",
    "\n",
    "    for key in list(model_state_dict.keys()):\n",
    "        if 'module.' in key:\n",
    "            model_state_dict[key.replace('module.','')] = model_state_dict[key]\n",
    "            del model_state_dict[key]\n",
    "            \n",
    "    model = my_2d1ddy(backbone_state_dict=backbone_state_dict, backbone_mode=backbone_mode,\n",
    "                                        embedding_dim=cnn1d_embedding_dim, channels=cnn1d_channels, modality=modality,\n",
    "                                        output_dim=output_dim, kernel_size=cnn1d_kernel_size, attention=cnn1d_attention,\n",
    "                                        dropout=cnn1d_dropout, root_dir=model_load_path)\n",
    "    model.init()\n",
    "    model.load_state_dict(model_state_dict)\n",
    "    \n",
    "    # dataset_path = \"../data/Affwild2/seed_data.json\"\n",
    "    dataset_path = \"Affwild2_processed_ver3\"\n",
    "\n",
    "    arranger = ABAW2_VA_Arranger(dataset_path, window_length=window_length, hop_length=hop_length,\n",
    "                                debug=debug)\n",
    "\n",
    "    mean_std_info = arranger.mean_std_info\n",
    "    data_dict = arranger.resample_according_to_window_and_hop_length(seed)\n",
    "\n",
    "    test_dataset = ABAW2_VA_Dataset(data_dict['Test_Set'], time_delay=time_delay,\n",
    "                                        emotion=train_emotion, modality=modality,\n",
    "                                        head=head, mode='validate', fold=fold, mean_std_info=mean_std_info)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model.cuda(device=device)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        outputs, trials_pred, loss, output_handler, continuous_label_handler, metric_handler = loop(test_loader, train_mode=False)\n",
    "        \n",
    "    metric_handler.calculate_metrics()\n",
    "    ccc_result = metric_handler.metric_record_dict\n",
    "    new_ccc_result = {} # {\"vid\" : [valence, arousal, mean]}\n",
    "    for k in ccc_result.keys():\n",
    "        new_ccc_result[k] = [ccc_result[k]['Valence']['ccc'][0], ccc_result[k]['Arousal']['ccc'][0], np.mean([ccc_result[k]['Valence']['ccc'][0], ccc_result[k]['Arousal']['ccc'][0]])]\n",
    "        \n",
    "    sort_vid = sorted(new_ccc_result.items(), key=lambda x: x[1][2])\n",
    "    \n",
    "    print(\"before sort_vid len : \", len(sort_vid))\n",
    "    for idx, i in enumerate(sort_vid):\n",
    "        if i[0] == 'overall':\n",
    "            del sort_vid[idx]\n",
    "            \n",
    "    print(\"after sort_vid len : \", len(sort_vid))\n",
    "    \n",
    "    valence = []\n",
    "    arousal = []\n",
    "    mean = []\n",
    "\n",
    "    for vid,score_list in sort_vid:    \n",
    "        valence.append(score_list[0])\n",
    "        arousal.append(score_list[1])\n",
    "        mean.append(score_list[2])\n",
    "        \n",
    "    val_std = np.round(np.std(valence), 3)\n",
    "    aro_std = np.round(np.std(arousal), 3)\n",
    "    mean_std = np.round(np.std(mean), 3)\n",
    "    \n",
    "    file_values_dict['Seed'].append(seed)\n",
    "    file_values_dict['CCC_Valence'].append(str(np.round(np.mean(valence), 3)) + \"±\" + str(val_std))\n",
    "    file_values_dict['CCC_Arousal'].append(str(np.round(np.mean(arousal), 3)) + \"±\" + str(aro_std))\n",
    "    file_values_dict['CCC_Mean'].append(str(np.round(np.mean(mean), 3)) + \"±\" + str(mean_std))\n",
    "    \n",
    "    print(file_values_dict['CCC_Valence'])\n",
    "    print(file_values_dict['CCC_Arousal'])\n",
    "    print(file_values_dict['CCC_Mean'])\n",
    "        \n",
    "full_record_df = pd.DataFrame(file_values_dict, columns=columns)\n",
    "full_record_df.to_csv(csv_name,  mode='a', header=False, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_mean :  0.382\n",
      "aro_mean :  0.43\n",
      "mean_mean :  0.406\n",
      "val_std :  0.023\n",
      "aro_std :  0.017\n",
      "mean_std :  0.018\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "char = \"±\"\n",
    "\n",
    "valence = []\n",
    "arousal = []\n",
    "mean = []\n",
    "\n",
    "for v, a, m in zip(file_values_dict['CCC_Valence'], file_values_dict['CCC_Arousal'], file_values_dict['CCC_Mean']):\n",
    "    v,a,m = float(v.split(char)[0]), float(a.split(char)[0]), float(m.split(char)[0])\n",
    "    valence.append(v)\n",
    "    arousal.append(a)\n",
    "    mean.append(m)\n",
    "    \n",
    "val_std =  np.round(np.std(valence), 3) \n",
    "aro_std =  np.round(np.std(arousal), 3)\n",
    "mean_std = np.round(np.std(mean), 3)\n",
    "\n",
    "val_mean = np.round(np.average(valence), 3) \n",
    "aro_mean = np.round(np.average(arousal), 3) \n",
    "mean_mean = np.round(np.average(mean), 3) \n",
    "\n",
    "print(\"val_mean : \", val_mean)\n",
    "print(\"aro_mean : \", aro_mean)\n",
    "print(\"mean_mean : \", mean_mean)\n",
    "print(\"val_std : \", val_std)\n",
    "print(\"aro_std : \", aro_std)\n",
    "print(\"mean_std : \", mean_std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "affwild_pre",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
